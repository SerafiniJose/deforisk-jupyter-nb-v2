{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d677a-7aea-4138-92cb-8b8d5745752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ghislainv/forestatrisk/tree/master/forestatrisk/data/compute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb9c20-89fb-4287-ab3e-2ce78cfe204d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROJ_LIB\"] = \"/usr/share/proj\"\n",
    "os.environ[\"GDAL_DATA\"] = \"/usr/share/gdal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDAL optimizations\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "cpu_count: int = multiprocessing.cpu_count()\n",
    "num_cores: int = cpu_count - 2\n",
    "os.environ[\"GDAL_NUM_THREADS\"] = f\"{num_cores}\"\n",
    "os.environ[\"GDAL_CACHEMAX\"] = \"1024\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff714b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "memory_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(psutil.virtual_memory().total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7482e31-e641-481d-b7ce-37c1ae376fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import ee\n",
    "import fiona\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from fiona.transform import transform_geom\n",
    "from osgeo import gdal\n",
    "from pyproj import Proj, transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77486029-cda3-4087-8c02-c371e1a4b601",
   "metadata": {},
   "source": [
    "## Connect folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80784bc3-9ddb-49d8-ab4e-eff3ce15bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder: Path = Path.cwd().parent\n",
    "downloads_folder: Path = root_folder / \"data\"\n",
    "downloads_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357db97-b9e1-480e-b80d-5427b18cbae5",
   "metadata": {},
   "source": [
    "## Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb7f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_name = \"MTQ\"\n",
    "# user_defined_epsg_code = \"5490\"\n",
    "# years = [2005, 2010, 2015]\n",
    "# tree_cover_threshold = 10\n",
    "# forest_source = \"gfc\"  ##gfc, tmf, mapbiomas\n",
    "# random_seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d357f-b300-4fbf-b440-9a21bb4889bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = downloads_folder / project_name\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "data_raw_folder = project_folder / \"data_raw\"\n",
    "data_raw_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_data_folder = project_folder / \"data\"\n",
    "processed_data_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ff094-9fb0-49cf-ad50-35174df271f8",
   "metadata": {},
   "source": [
    "## Calculate epsg code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d33817-9be8-4070-9786-23b777fab4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "\n",
    "def get_centroid(shapefile_path):\n",
    "    \"\"\"\n",
    "    Get the centroid of the first feature in a shapefile using Shapely and Fiona.\n",
    "\n",
    "    Parameters:\n",
    "        shapefile_path (str): Path to the input shapefile.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the latitude and longitude of the centroid.\n",
    "    \"\"\"\n",
    "    # Open the shapefile\n",
    "    with fiona.open(shapefile_path, \"r\") as shapefile:\n",
    "        # Get the first feature\n",
    "        first_feature = next(iter(shapefile))\n",
    "\n",
    "        # Convert the feature geometry to a Shapely geometry object\n",
    "        geom = shape(first_feature[\"geometry\"])\n",
    "\n",
    "        # Calculate the centroid\n",
    "        centroid = geom.centroid\n",
    "\n",
    "        # Get the coordinates of the centroid\n",
    "        longitude, latitude = centroid.x, centroid.y\n",
    "\n",
    "    return (longitude, latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b9cbf-793c-4dc5-8327-e3ff02fdff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utm_proj_str_from_lat_lon(lon, lat):\n",
    "    \"\"\"\n",
    "    Given a longitude, latitude in WGS84, return the EPSG code as a string\n",
    "    for the corresponding UTM or UPS projection.\n",
    "\n",
    "    - UTM: EPSG:326xx (Northern) or EPSG:327xx (Southern)\n",
    "    - UPS: EPSG:5041 (North, >84°N), EPSG:5042 (South, <–80°S)\n",
    "\n",
    "    Handles special cases for Norway and Svalbard.\n",
    "    \"\"\"\n",
    "    # UPS zones for polar regions\n",
    "    if lat >= 84:\n",
    "        return \"EPSG:5041\"  # UPS North\n",
    "    elif lat <= -80:\n",
    "        return \"EPSG:5042\"  # UPS South\n",
    "\n",
    "    # Special cases for Norway and Svalbard\n",
    "    if lat > 55 and lat < 64 and lon > 2 and lon < 6:\n",
    "        zone_number = 32\n",
    "    elif lat > 71 and lon >= 6 and lon < 9:\n",
    "        zone_number = 31\n",
    "    elif lat > 71 and ((lon >= 9 and lon < 12) or (lon >= 18 and lon < 21)):\n",
    "        zone_number = 33\n",
    "    elif lat > 71 and ((lon >= 21 and lon < 24) or (lon >= 30 and lon < 33)):\n",
    "        zone_number = 35\n",
    "    else:\n",
    "        zone_number = int((lon + 180) / 6) + 1\n",
    "\n",
    "    if lat >= 0:\n",
    "        epsg_code = 32600 + zone_number  # Northern Hemisphere\n",
    "    else:\n",
    "        epsg_code = 32700 + zone_number  # Southern Hemisphere\n",
    "\n",
    "    return epsg_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad62ce-2157-4d26-a3a8-b7be8149b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_centroid = get_centroid(str(data_raw_folder) + \"/\" + project_name + \"_aoi.shp\")\n",
    "calculated_epsg = get_utm_proj_str_from_lat_lon(aoi_centroid[0], aoi_centroid[1])\n",
    "calculated_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0f71f-3757-4cfd-936e-1ff3abd9ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_code = user_defined_epsg_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab30d0-e6ad-42a1-aa2d-f300b8381faf",
   "metadata": {},
   "source": [
    "## Filter files helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293112e-f359-414f-8ea0-d83c2e3aa468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_by_extension(folder_path, file_extensions):\n",
    "    \"\"\"\n",
    "    List all files with specified extensions in the given folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder where you want to search for files.\n",
    "    file_extensions (list of str): A list of file extensions to search for (e.g., ['.shp', '.tif']).\n",
    "\n",
    "    Returns:\n",
    "    list: A list of file paths with the specified extensions.\n",
    "    \"\"\"\n",
    "    matching_files = []\n",
    "    try:\n",
    "        # Check if the provided path is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Iterate over all files in the directory\n",
    "            for filename in os.listdir(folder_path):\n",
    "                # Construct full file path\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                # Check if the file has any of the specified extensions\n",
    "                if any(filename.lower().endswith(ext) for ext in file_extensions):\n",
    "                    matching_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"The provided path '{folder_path}' is not a directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return matching_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304802a6-81bd-4ec2-a2c1-2299de9e9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_files(input_files, filter_words, exclude_words=None):\n",
    "    \"\"\"\n",
    "    Filters a list of files based on include and exclude words.\n",
    "\n",
    "    Parameters:\n",
    "        input_files (list): List of file paths to be filtered.\n",
    "        filter_words (list): Words that must be present in the filenames for inclusion.\n",
    "        exclude_words (list, optional): Words that must not be present in the filenames for exclusion. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: Filtered list of files.\n",
    "    \"\"\"\n",
    "    # Ensure all words are lowercase for case-insensitive comparison\n",
    "    filter_words = [word.lower() for word in filter_words]\n",
    "    exclude_words = [word.lower() for word in (exclude_words or [])]\n",
    "\n",
    "    filtered_files = [\n",
    "        file\n",
    "        for file in input_files\n",
    "        if all(word in os.path.basename(file).lower() for word in filter_words)\n",
    "        and not any(\n",
    "            exclude_word in os.path.basename(file).lower()\n",
    "            for exclude_word in exclude_words\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return filtered_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3949a42-decf-4f32-b096-c75731531eb6",
   "metadata": {},
   "source": [
    "## Reproject Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d574a9-e28e-4199-bac7-474b7f1b5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_shapefile(input_shapefile, output_shapefile, target_epsg):\n",
    "    # Open the input shapefile\n",
    "    with fiona.open(input_shapefile, \"r\") as src:\n",
    "        # Get the source CRS\n",
    "        src_crs = src.crs\n",
    "        # Define the target CRS\n",
    "        target_crs = f\"EPSG:{target_epsg}\"\n",
    "\n",
    "        # Define the transformation function\n",
    "        project = lambda geom: transform_geom(src_crs, target_crs, geom)\n",
    "\n",
    "        # Open the output shapefile for writing\n",
    "        with fiona.open(\n",
    "            output_shapefile,\n",
    "            \"w\",\n",
    "            crs=target_crs,\n",
    "            driver=\"ESRI Shapefile\",\n",
    "            schema=src.schema,\n",
    "        ) as dst:\n",
    "            # Iterate over features in the source shapefile\n",
    "            for feature in src:\n",
    "                # Transform the geometry and create a new feature\n",
    "                new_feature = {**feature, \"geometry\": project(feature[\"geometry\"])}\n",
    "                # Write the transformed feature to the output shapefile\n",
    "                dst.write(new_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1cdf8-9870-4b77-b024-7f60fdf1fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_shp_files(shp_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Process .shp files by generating corresponding .tif filenames and calling rasterize_vectors.\n",
    "\n",
    "    Parameters:\n",
    "    shp_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "    \"\"\"\n",
    "    shp_files = list_files_by_extension(shp_folder, [\".shp\"])\n",
    "    for shp_file in shp_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        reprojected_filename = f\"{base_name}_reprojected.shp\"\n",
    "        reprojected_path = os.path.join(tif_folder, reprojected_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_shapefile(shp_file, reprojected_path, target_epsg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97c634-bff1-47d9-912f-d5f58cee1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_shp_files(data_raw_folder, processed_data_folder, epsg_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eec285-447d-48f4-a75c-79d7657cc413",
   "metadata": {},
   "source": [
    "## Reproject Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021e72b-6113-4e3c-ad0c-ee549965913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def reproject_raster_gdal(input_file, output_file, target_epsg):\n",
    "    \"\"\"\n",
    "    Reprojects a raster file to a specified EPSG code using GDAL and saves it with DEFLATE compression.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input raster file.\n",
    "    output_file (str): The path where the reprojected raster file will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Open the input dataset\n",
    "    dataset = gdal.Open(input_file)\n",
    "    if not dataset:\n",
    "        raise FileNotFoundError(f\"Input file {input_file} not found.\")\n",
    "\n",
    "    # Get projection and geotransform from the original raster\n",
    "    src_proj = dataset.GetProjection()\n",
    "    src_geotrans = dataset.GetGeoTransform()\n",
    "    # print(dataset.GetRasterBand(1).DataType)\n",
    "    # Create the output dataset with the target EPSG and DEFLATE compression\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    out_dataset = driver.Create(\n",
    "        output_file,\n",
    "        dataset.RasterXSize,\n",
    "        dataset.RasterYSize,\n",
    "        dataset.RasterCount,\n",
    "        dataset.GetRasterBand(1).DataType,\n",
    "        [\"COMPRESS=DEFLATE\"],\n",
    "    )\n",
    "\n",
    "    # Set projection and geotransform for the output dataset\n",
    "    out_proj = f\"EPSG:{target_epsg}\"\n",
    "    out_geotrans = src_geotrans  # Assuming same resolution and extent\n",
    "\n",
    "    out_dataset.SetProjection(out_proj)\n",
    "    out_dataset.SetGeoTransform(out_geotrans)\n",
    "\n",
    "    # Perform reprojection\n",
    "    gdal.ReprojectImage(\n",
    "        dataset, out_dataset, src_proj, out_proj, gdal.GRA_NearestNeighbour\n",
    "    )\n",
    "\n",
    "    # Close datasets\n",
    "    dataset = None\n",
    "    out_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def reproject_raster_gdal_warp(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    target_epsg: str,\n",
    "    target_x: int | float = 30,\n",
    "    target_y: int | float = 30,\n",
    "    resampling_method: str = \"near\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reprojects a raster file to a specified EPSG code using GDAL and saves it with DEFLATE compression.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input raster file.\n",
    "    output_file (str): The path where the reprojected raster file will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Get system information for optimization\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    # Determine optimal number of cores (use 4 or less, or available cores)\n",
    "    num_cores = cpu_count - 2\n",
    "\n",
    "    # Open the input dataset\n",
    "    dataset = gdal.Open(input_file)\n",
    "    if not dataset:\n",
    "        raise FileNotFoundError(f\"Input file {input_file} not found.\")\n",
    "\n",
    "    # Get projection and geotransform from the original raster\n",
    "    src_proj = dataset.GetProjection()\n",
    "\n",
    "    # Callback\n",
    "    param = gdal.WarpOptions(\n",
    "        warpOptions=[\"overwrite\"],\n",
    "        srcSRS=src_proj,\n",
    "        dstSRS=f\"EPSG:{target_epsg}\",\n",
    "        targetAlignedPixels=True,\n",
    "        resampleAlg=resampling_method,\n",
    "        xRes=target_x,\n",
    "        yRes=target_y,\n",
    "        multithread=True,\n",
    "        warpMemoryLimit=500 * num_cores,\n",
    "        creationOptions=[\n",
    "            \"COMPRESS=DEFLATE\",\n",
    "            \"PREDICTOR=2\",\n",
    "            \"BIGTIFF=YES\",\n",
    "            f\"NUM_THREADS={num_cores}\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Perform reprojection\n",
    "    gdal.Warp(output_file, input_file, format=\"GTiff\", options=param)\n",
    "\n",
    "    # Close datasets\n",
    "    dataset = None\n",
    "    out_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf8687-ece4-4e22-976a-62b8b6f1696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import Resampling, calculate_default_transform, reproject\n",
    "\n",
    "\n",
    "def reproject_raster_rasterio(input_file, output_file, target_epsg):\n",
    "    \"\"\"\n",
    "    Reprojects a raster file to a specified EPSG code using Rasterio and saves it with DEFLATE compression.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input raster file.\n",
    "    output_file (str): The path where the reprojected raster file will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_file) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, f\"EPSG:{target_epsg}\", src.width, src.height, *src.bounds\n",
    "        )\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update(\n",
    "            {\n",
    "                \"crs\": f\"EPSG:{target_epsg}\",\n",
    "                \"transform\": transform,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"compress\": \"deflate\",  # Enable DEFLATE compression\n",
    "            }\n",
    "        )\n",
    "\n",
    "        with rasterio.open(output_file, \"w\", **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=f\"EPSG:{target_epsg}\",\n",
    "                    resampling=Resampling.nearest,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301e1eb-4f85-4db1-a1bd-fa0b8a8d841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_near(input_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "    # Define the words to filter by\n",
    "    filter_words = [\"town\", \"rivers\", \"roads\", \"wdpa\", forest_source]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_raster_gdal_warp(raster_file, tif_path, target_epsg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_bilinear(input_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "    # Define the words to filter by\n",
    "    filter_words = [\"altitude\", \"slope\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_raster_gdal_warp(\n",
    "            raster_file, tif_path, target_epsg, resampling_method=\"bilinear\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3d779-dc25-4656-9867-6cb80311e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_bilinear(data_raw_folder, processed_data_folder, epsg_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb682a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_near(data_raw_folder, processed_data_folder, epsg_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c1ef13-4f8c-4cf0-9068-d27bb909daa3",
   "metadata": {},
   "source": [
    "## Rasterize Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05862521-9766-47bc-b3b0-fdbbae94b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "\n",
    "def rasterize_binary_orig(vector_path, output_raster_path, pixel_size=30):\n",
    "    \"\"\"\n",
    "    Rasterize a vector file to a raster file using Rasterio.\n",
    "\n",
    "    Parameters:\n",
    "        vector_path (str): Path to the input vector file.\n",
    "        output_raster_path (str): Path to the output raster file.\n",
    "        pixel_size (float): Pixel size of the output raster. Default is 30.\n",
    "    \"\"\"\n",
    "    # Open the vector file\n",
    "    with fiona.open(vector_path, \"r\") as shapefile:\n",
    "        # Get the bounding box of the vector file\n",
    "        bounds = shapefile.bounds\n",
    "\n",
    "        # Ensure valid bounding box dimensions\n",
    "        if (bounds[2] - bounds[0]) == 0 or (bounds[3] - bounds[1]) == 0:\n",
    "            raise ValueError(\n",
    "                \"Invalid bounding box dimensions. The bounding box has zero width or height.\"\n",
    "            )\n",
    "\n",
    "        # Calculate the width and height of the output raster\n",
    "        width = int((bounds[2] - bounds[0]) / pixel_size)\n",
    "        height = int((bounds[3] - bounds[1]) / pixel_size)\n",
    "\n",
    "        # Create an empty array to hold the raster data\n",
    "        raster_data = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        # Rasterize each feature in the shapefile\n",
    "        for feature in shapefile:\n",
    "            geom = feature[\"geometry\"]\n",
    "            value = 1  # Set all features to 1\n",
    "            shapes = [(geom, value)]\n",
    "            rasterize(\n",
    "                shapes=shapes,\n",
    "                out=raster_data,\n",
    "                fill=0,\n",
    "                transform=from_bounds(*bounds, width, height),\n",
    "            )\n",
    "\n",
    "    # Write the raster data to a file\n",
    "    with rasterio.open(\n",
    "        output_raster_path,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=np.uint8,\n",
    "        crs=shapefile.crs,\n",
    "        transform=from_bounds(*bounds, width, height),\n",
    "        compress=\"deflate\",\n",
    "    ) as dst:\n",
    "        dst.write(raster_data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5547fb-34df-4de9-b289-8ff80e0851b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "\n",
    "def rasterize_binary(vector_path, extent_file, output_raster_path, pixel_size=30):\n",
    "    \"\"\"\n",
    "    Rasterize a vector file to a raster file using Rasterio.\n",
    "    Parameters:\n",
    "        vector_path (str): Path to the input vector file.\n",
    "        output_raster_path (str): Path to the output raster file.\n",
    "        fcc_file (str): Path to the reference raster file for resolution and extent.\n",
    "        pixel_size (float): Pixel size of the output raster. Default is 30.\n",
    "    \"\"\"\n",
    "    # Open the reference raster file\n",
    "    with rasterio.open(extent_file) as src:\n",
    "        gt = src.transform\n",
    "        xmin, ymin, xmax, ymax = src.bounds\n",
    "        xres = gt[0]\n",
    "        yres = -gt[4]\n",
    "\n",
    "    # Calculate the width and height of the output raster based on the reference raster's resolution\n",
    "    width = int((xmax - xmin) / xres)\n",
    "    height = int((ymax - ymin) / yres)\n",
    "\n",
    "    # Create an empty array to hold the raster data\n",
    "    raster_data = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Open the vector file\n",
    "    with fiona.open(vector_path, \"r\") as shapefile:\n",
    "        # Rasterize each feature in the shapefile\n",
    "        for feature in shapefile:\n",
    "            geom = feature[\"geometry\"]\n",
    "            value = 1  # Set all features to 1\n",
    "            shapes = [(geom, value)]\n",
    "            rasterize(\n",
    "                shapes=shapes,\n",
    "                out=raster_data,\n",
    "                fill=0,\n",
    "                transform=from_bounds(xmin, ymin, xmax, ymax, width, height),\n",
    "            )\n",
    "\n",
    "    # Write the raster data to a file\n",
    "    with rasterio.open(\n",
    "        output_raster_path,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=np.uint8,\n",
    "        crs=shapefile.crs,\n",
    "        transform=from_bounds(xmin, ymin, xmax, ymax, width, height),\n",
    "        compress=\"deflate\",\n",
    "    ) as dst:\n",
    "        dst.write(raster_data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb575b-912a-40e8-ba62-9fa49eb5667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "\n",
    "def rasterize_unique_id(input_file, extent_file, output_file):\n",
    "    \"\"\"Rasterizing subjurisdictions using Rasterio.\n",
    "    Parameters:\n",
    "        input_file: Input shapefile with subjurisdictions.\n",
    "        fcc_file: Input reference file for resolution and extent.\n",
    "        output_file: Output raster file with integer id for subjurisdictions.\n",
    "    \"\"\"\n",
    "    # Open the reference raster file\n",
    "    with rasterio.open(extent_file) as src:\n",
    "        gt = src.transform\n",
    "        xmin, ymin, xmax, ymax = src.bounds\n",
    "        xres = gt[0]\n",
    "        yres = -gt[4]\n",
    "\n",
    "    # Read the shapefile\n",
    "    with fiona.open(input_file, \"r\") as shp:\n",
    "        features = [feature[\"geometry\"] for feature in shp]\n",
    "\n",
    "    # Create an output raster\n",
    "    transform = from_bounds(xmin, ymin, xmax, ymax, src.width, src.height)\n",
    "    out_meta = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"count\": 1,\n",
    "        \"height\": src.height,\n",
    "        \"width\": src.width,\n",
    "        \"transform\": transform,\n",
    "        \"crs\": src.crs,\n",
    "        \"dtype\": rasterio.uint8,\n",
    "        \"compress\": \"deflate\",\n",
    "    }\n",
    "\n",
    "    # Rasterize the features\n",
    "    out_image = rasterize(\n",
    "        [(geom, value) for geom, value in zip(features, range(1, len(features) + 1))],\n",
    "        out_shape=(src.height, src.width),\n",
    "        fill=0,\n",
    "        transform=transform,\n",
    "        dtype=rasterio.uint8,\n",
    "    )\n",
    "\n",
    "    # Write the output raster file\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dst:\n",
    "        dst.write(out_image, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65c620-57a1-4f33-bab8-32379af23ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_shp_files(shp_folder, tif_folder):\n",
    "    \"\"\"\n",
    "    Process .shp files by generating corresponding .tif filenames and calling rasterize_vectors.\n",
    "\n",
    "    Parameters:\n",
    "    shp_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "    \"\"\"\n",
    "    shp_files = list_files_by_extension(shp_folder, [\".shp\"])\n",
    "\n",
    "    shp_files_binary = filter_files(shp_files, [\"aoi\"])\n",
    "\n",
    "    reference_forest_file = filter_files(\n",
    "        list_files_by_extension(processed_data_folder, [\".tiff\", \".tif\"]),\n",
    "        [\"reprojected\", forest_source],\n",
    "    )[0]\n",
    "\n",
    "    for shp_file in shp_files_binary:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        rasterize_binary(shp_file, reference_forest_file, tif_path)\n",
    "\n",
    "    shp_files_unique = filter_files(shp_files, [\"subj\"])\n",
    "\n",
    "    for shp_file in shp_files_unique:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        rasterize_unique_id(shp_file, reference_forest_file, tif_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0fec6-e1cb-4423-9a26-4daaa3b782df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterize_shp_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5896b-e3cc-4d9d-8ced-723800b4cb79",
   "metadata": {},
   "source": [
    "## Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2eab5-9788-4e6a-8c33-0cd2ac323377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "\n",
    "def distance_to_edge_rasterio(input_file, dist_file):\n",
    "    \"\"\"Computing the shortest distance to pixels with given values in a raster file.\n",
    "\n",
    "    This function computes the shortest distance to pixels with given values in a raster file. Distances generated are in georeferenced coordinates.\n",
    "\n",
    "    :param input_file: Input raster file.\n",
    "\n",
    "    :param dist_file: Path to the distance raster file that is created.\n",
    "\n",
    "    :return: None. A distance raster file is created (see ``dist_file``). Raster data type is UInt32 ([0, 4294967295]). NoData is set to zero.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    with rasterio.open(input_file) as src:\n",
    "        src_data = src.read(1)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "        # Create a mask array where the values match those specified\n",
    "        values = 0\n",
    "        mask = np.isin(src_data, values)\n",
    "\n",
    "        # Initialize distance array with NoData value (0)\n",
    "        dist_data = np.zeros_like(src_data, dtype=np.uint32)\n",
    "\n",
    "        # Calculate the shortest distance (this is a simplified approach)\n",
    "        dist_data = distance_transform_edt(~mask) * transform.a  # Scale by pixel size\n",
    "\n",
    "    # Write output file\n",
    "    with rasterio.open(\n",
    "        dist_file,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=src_data.shape[0],\n",
    "        width=src_data.shape[1],\n",
    "        count=1,\n",
    "        dtype=np.uint32,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress=\"lzw\",\n",
    "        predictor=2,\n",
    "    ) as dst:\n",
    "        dst.write(dist_data, 1)\n",
    "        dst.nodata = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19725b0-001e-4c4d-ac82-ea8fef07c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_no_forest_rasterio(input_file, dist_file):\n",
    "    \"\"\"\n",
    "    For each forest pixel (value = 1), compute shortest distance to nearest non-forest pixel (value = 0).\n",
    "    Preserves original NoData mask: output is 0 where input was NoData.\n",
    "\n",
    "    :param input_file: Input raster path (forest=1, no forest=0)\n",
    "    :param dist_file: Output distance raster path\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_file) as src:\n",
    "        data = src.read(1).astype(np.float32)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        nodata = src.nodata\n",
    "\n",
    "        # Step 1: Define valid pixels (not NoData)\n",
    "        if nodata is not None:\n",
    "            valid_mask = ~np.isclose(data, nodata)\n",
    "        else:\n",
    "            valid_mask = np.ones_like(data, dtype=bool)\n",
    "\n",
    "        # print(f\"Valid pixels: {valid_mask.sum()} out of {data.size}\")\n",
    "\n",
    "        # Step 2: Define target pixels (non-forest): value == 0 AND not NoData\n",
    "        targets = np.logical_and(data == 0, valid_mask)\n",
    "        print(f\"Target (no forest) pixels: {targets.sum()}\")\n",
    "\n",
    "        if not targets.any():\n",
    "            raise ValueError(\"No non-forest (value=0) pixels found in valid area!\")\n",
    "\n",
    "        # Step 3: Prepare distance transform input\n",
    "        # We compute distances from all valid pixels to nearest target (non-forest)\n",
    "        # So we create a grid where:\n",
    "        #   - All valid pixels are allowed (True)\n",
    "        #   - But targets themselves are marked as source → set to False in the EDT input\n",
    "\n",
    "        edt_input = np.zeros_like(data, dtype=bool)\n",
    "        edt_input[valid_mask] = True  # Only compute within valid area\n",
    "        edt_input[targets] = False  # Target pixels: set to False (sources)\n",
    "\n",
    "        print(f\"EDT input size: {edt_input.sum()} pixels\")\n",
    "\n",
    "        if not edt_input.any():\n",
    "            raise ValueError(\"No non-target valid pixels left!\")\n",
    "\n",
    "        # Step 4: Compute distance transform in georeferenced units\n",
    "        try:\n",
    "            dist_array = distance_transform_edt(edt_input) * abs(transform.a)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Distance transform failed: {e}\")\n",
    "\n",
    "        # Step 5: Output only for valid forest pixels (value == 1), set others to 0\n",
    "        dist_data = np.zeros_like(data, dtype=np.uint32)\n",
    "\n",
    "        # Only assign distance where data == 1 AND valid\n",
    "        forest_pixels = np.logical_and(data == 1, valid_mask)\n",
    "        # print(f\"Forest pixels: {forest_pixels.sum()}\")\n",
    "\n",
    "        if forest_pixels.any():\n",
    "            dist_data[forest_pixels] = dist_array[forest_pixels].astype(np.uint32)\n",
    "\n",
    "        # Preserve original NoData in output (set to 0)\n",
    "        if nodata is not None:\n",
    "            dist_data[np.isclose(data, nodata)] = 0\n",
    "\n",
    "    # Write output\n",
    "    with rasterio.open(\n",
    "        dist_file,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=data.shape[0],\n",
    "        width=data.shape[1],\n",
    "        count=1,\n",
    "        dtype=np.uint32,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress=\"lzw\",\n",
    "        predictor=2,\n",
    "        nodata=0,\n",
    "    ) as dst:\n",
    "        dst.write(dist_data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d0637-894f-4460-8954-323afcb2eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_edge_gdal(input_file, dist_file):\n",
    "    \"\"\"Computing the shortest distance to pixels with given values in\n",
    "    a raster file.\n",
    "\n",
    "    This function computes the shortest distance to pixels with given\n",
    "    values in a raster file. Distances generated are in georeferenced\n",
    "    coordinates.\n",
    "\n",
    "    :param input_file: Input raster file.\n",
    "\n",
    "    :param dist_file: Path to the distance raster file that is\n",
    "        created.\n",
    "\n",
    "    :return: None. A distance raster file is created (see\n",
    "        ``dist_file``). Raster data type is UInt32 ([0,\n",
    "        4294967295]). NoData is set to zero.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    src_ds = gdal.Open(input_file)\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create raster of distance\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=LZW\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(src_ds.GetProjectionRef())\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Compute distance\n",
    "    values = [0]\n",
    "    val_as_string = \",\".join([str(i) for i in values])\n",
    "    val = \"VALUES=\" + val_as_string\n",
    "    gdal.ComputeProximity(srcband, dstband, [val, \"DISTUNITS=GEO\"])\n",
    "\n",
    "    # Set nodata value\n",
    "    dstband.SetNoDataValue(0)\n",
    "\n",
    "    # Delete objects\n",
    "    srcband = None\n",
    "    dstband = None\n",
    "    del src_ds, dst_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9ee3a-72ed-4c04-a675-b1580116440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def distance_to_edge_gdal_revised(\n",
    "    input_file, dist_file, values=0, nodata=4294967295, input_nodata=True, verbose=False\n",
    "):\n",
    "    \"\"\"Computes the shortest distance to given pixel values in a raster,\n",
    "    while preserving the original nodata mask in the output.\"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    src_ds = gdal.Open(input_file)\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create raster of distance\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=DEFLATE\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(src_ds.GetProjection())\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Use_input_nodata\n",
    "    ui_nodata = \"YES\" if input_nodata else \"NO\"\n",
    "\n",
    "    # Compute distance\n",
    "    val = \"VALUES=\" + str(values)\n",
    "    use_input_nodata = \"USE_INPUT_NODATA=\" + ui_nodata\n",
    "    cb = gdal.TermProgress_nocb if verbose else 0\n",
    "    gdal.ComputeProximity(\n",
    "        srcband, dstband, [val, use_input_nodata, \"DISTUNITS=GEO\"], callback=cb\n",
    "    )\n",
    "\n",
    "    # Inlcude values as part of the mask\n",
    "    # Read data as array\n",
    "    src_arr = srcband.ReadAsArray()\n",
    "    dst_arr = dstband.ReadAsArray()\n",
    "    # Mask nodata\n",
    "    # Ensure values is iterable (list/ndarray)\n",
    "    values = [values] if np.isscalar(values) else values\n",
    "    dst_arr[np.isin(src_arr, values)] = nodata\n",
    "    # Write back masked result\n",
    "    dstband.WriteArray(dst_arr)\n",
    "\n",
    "    # Set nodata value\n",
    "    dstband.SetNoDataValue(nodata)\n",
    "\n",
    "    # Flush to disk\n",
    "    dstband.FlushCache()\n",
    "    dst_ds.FlushCache()\n",
    "\n",
    "    # Clean up\n",
    "    srcband = None\n",
    "    dstband = None\n",
    "    del src_ds, dst_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc037203-bbf8-436a-acf1-e3f6ea043f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "\n",
    "def distance_from_outside(input_file, output_file):\n",
    "    # Open the input raster file\n",
    "    with rasterio.open(input_file) as src:\n",
    "        roads = src.read(1)\n",
    "        mask = src.read_masks(1) == 0  # True where pixels are masked (nodata)\n",
    "\n",
    "        # Identify road and non-road pixels\n",
    "        no_roads = roads == 0\n",
    "\n",
    "        # Calculate distance from each no-road pixel to the nearest road pixel\n",
    "        distances = distance_transform_edt(no_roads, sampling=src.transform.a)\n",
    "\n",
    "        # Apply the original mask to the distance array\n",
    "        distances = np.where(\n",
    "            mask, src.nodata if src.nodata is not None else np.nan, distances\n",
    "        )\n",
    "\n",
    "    # Write the output raster file\n",
    "    with rasterio.open(\n",
    "        output_file,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=distances.shape[0],\n",
    "        width=distances.shape[1],\n",
    "        count=1,\n",
    "        dtype=rasterio.float32,\n",
    "        crs=src.crs,\n",
    "        transform=src.transform,\n",
    "        nodata=src.nodata if src.nodata is not None else None,\n",
    "    ) as dst:\n",
    "        dst.write(distances.astype(rasterio.float32), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d59be4-92fc-4d80-8527-ad93597db8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_from_outside_gdal(input_file, dist_file):\n",
    "    \"\"\"\n",
    "    Compute shortest distance from each non-road pixel (value=0) to nearest road pixel (value=1),\n",
    "    respecting NoData values and geospatial metadata.\n",
    "\n",
    "    This function now matches `distance_from_outside` in behavior:\n",
    "      - Only outputs distances where input == 0 AND valid\n",
    "      - Preserves original NoData mask\n",
    "      - Uses georeferenced units via DISTUNITS=GEO\n",
    "\n",
    "    :param input_file: Input raster (roads=1, no roads=0)\n",
    "    :param dist_file: Output distance raster path (GTiff)\n",
    "    \"\"\"\n",
    "    from osgeo import gdal\n",
    "\n",
    "    # Open input dataset\n",
    "    src_ds = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
    "    if not src_ds:\n",
    "        raise FileNotFoundError(f\"Could not open {input_file}\")\n",
    "\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    x_size = src_ds.RasterXSize\n",
    "    y_size = src_ds.RasterYSize\n",
    "    geotransform = src_ds.GetGeoTransform()\n",
    "    projection = src_ds.GetProjectionRef()\n",
    "    nodata_value = srcband.GetNoDataValue()\n",
    "\n",
    "    # Read data as numpy array\n",
    "    data_array = srcband.ReadAsArray().astype(np.float32)\n",
    "\n",
    "    # Create valid mask: not NoData and value == 0 (source)\n",
    "    if nodata_value is not None:\n",
    "        valid_mask = (data_array != nodata_value) & (data_array == 0)\n",
    "    else:\n",
    "        valid_mask = data_array == 0\n",
    "\n",
    "    # Step 1: Compute distance from value=0 to nearest value=1\n",
    "    # We need: source = value=0 → so use VALUES=0 in ComputeProximity\n",
    "\n",
    "    # Create temporary output dataset for proximity result\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        x_size,\n",
    "        y_size,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=LZW\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(geotransform)\n",
    "    dst_ds.SetProjection(projection)\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Set NoData value to 0 (we'll overwrite it later per input mask)\n",
    "    dstband.SetNoDataValue(0)\n",
    "\n",
    "    # Compute proximity from pixels with value=0\n",
    "    values = [0]\n",
    "    val_as_string = \",\".join([str(i) for i in values])\n",
    "    gdal.ComputeProximity(\n",
    "        srcband, dstband, [\"VALUES=\" + val_as_string, \"DISTUNITS=GEO\"]\n",
    "    )\n",
    "\n",
    "    # Read computed distances\n",
    "    dist_array = dstband.ReadAsArray().astype(np.uint32)\n",
    "\n",
    "    # Step 2: Final masking — only keep output where input was value=0 AND valid\n",
    "    final_data = np.zeros_like(dist_array, dtype=np.uint32)\n",
    "\n",
    "    if valid_mask.any():\n",
    "        final_data[valid_mask] = dist_array[valid_mask]\n",
    "\n",
    "    # Step 3: Apply original NoData mask\n",
    "    if nodata_value is not None:\n",
    "        no_data_mask = data_array == nodata_value\n",
    "        final_data[no_data_mask] = 0  # or set to nodata later\n",
    "\n",
    "    # Write output with correct data type and NoData setting\n",
    "    dstband.WriteArray(final_data)\n",
    "\n",
    "    # Now, write the dataset with proper NoData value in metadata\n",
    "    # But since we're using UInt32, and want to preserve original NoData,\n",
    "    # we must set it explicitly. However, GDAL doesn't allow NaN.\n",
    "    # So use 0 as NoData only if needed.\n",
    "\n",
    "    # To match rasterio output (which supports float32 with actual nodata), we should\n",
    "    # write the final_data as Float32 instead of UInt32 to support `nodata` correctly\n",
    "\n",
    "    # 🔥 IMPORTANT: Change output type to Float32 to allow proper NoData handling\n",
    "    dst_ds = None  # Close previous dataset\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        x_size,\n",
    "        y_size,\n",
    "        1,\n",
    "        gdal.GDT_Float32,\n",
    "        [\"COMPRESS=LZW\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(geotransform)\n",
    "    dst_ds.SetProjection(projection)\n",
    "\n",
    "    out_band = dst_ds.GetRasterBand(1)\n",
    "    # Convert final_data to float32\n",
    "    final_float = final_data.astype(np.float32)\n",
    "    out_band.WriteArray(final_float)\n",
    "\n",
    "    if nodata_value is not None:\n",
    "        out_band.SetNoDataValue(nodata_value)\n",
    "    else:\n",
    "        out_band.SetNoDataValue(None)  # optional\n",
    "\n",
    "    # Clean up\n",
    "    srcband = None\n",
    "    out_band = None\n",
    "    del src_ds, dst_ds\n",
    "\n",
    "    print(f\"Distance raster saved to: {dist_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182749f-474c-49a3-be6d-38bcb66c130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_edge_gdal_no_mask(\n",
    "    input_file,\n",
    "    dist_file,\n",
    "    values=0,\n",
    "    nodata=0,\n",
    "    max_distance_value=4294967295,\n",
    "    input_nodata=True,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Computes the shortest distance to given pixel values in a raster,\n",
    "    while preserving the original nodata mask in the output.\"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    src_ds = gdal.Open(input_file)\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create raster of distance\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=DEFLATE\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(src_ds.GetProjection())\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Use_input_nodata\n",
    "    ui_nodata = \"YES\" if input_nodata else \"NO\"\n",
    "\n",
    "    # Compute distance\n",
    "    val = \"VALUES=\" + str(values)\n",
    "    use_input_nodata = \"USE_INPUT_NODATA=\" + ui_nodata\n",
    "    max_distance = \"MAXDIST=\" + str(max_distance_value)\n",
    "    distance_nodata = \"NODATA=\" + str(nodata)\n",
    "    cb = gdal.TermProgress_nocb if verbose else 0\n",
    "    gdal.ComputeProximity(\n",
    "        srcband,\n",
    "        dstband,\n",
    "        [val, use_input_nodata, max_distance, distance_nodata, \"DISTUNITS=GEO\"],\n",
    "        callback=cb,\n",
    "    )\n",
    "\n",
    "    # Set nodata value\n",
    "    dstband.SetNoDataValue(max_distance_value)\n",
    "\n",
    "    # Flush to disk\n",
    "    dstband.FlushCache()\n",
    "    dst_ds.FlushCache()\n",
    "\n",
    "    # Clean up\n",
    "    srcband = None\n",
    "    dstband = None\n",
    "    del src_ds, dst_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55afe4-d253-4154-9222-925ec1bd4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = [\"forest\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_edge.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        # distance_to_no_forest_rasterio(raster_file, tif_path)\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee1c7c-3c24-44aa-8a9c-e2980627a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = [\"rivers\", \"roads\", \"town\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_distance.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        # distance_from_outside(raster_file, tif_path)\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5f41-2836-465c-9321-5291564843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_tif_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f133c-b57a-46dc-a5c9-728d440da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance_tif_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320ca0c-fa59-4587-a412-10ff833335b5",
   "metadata": {},
   "source": [
    "## Calculate Forest Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685733b-d5a5-49fe-abd9-1cadde48c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def process_forest_loss(input1_path, input2_path, output_path):\n",
    "    # Open the input rasters\n",
    "    with rasterio.open(input1_path) as src1:\n",
    "        input1 = src1.read(1)\n",
    "        bounds1 = src1.bounds\n",
    "        profile = src1.profile\n",
    "        nodata1 = src1.nodata\n",
    "\n",
    "    with rasterio.open(input2_path) as src2:\n",
    "        input2 = src2.read(1)\n",
    "        bounds2 = src2.bounds\n",
    "        nodata2 = src2.nodata\n",
    "\n",
    "    # Check if the bounds of input1 are equal to or larger than those of input2\n",
    "    if not (\n",
    "        bounds1.left <= bounds2.left\n",
    "        and bounds1.right >= bounds2.right\n",
    "        and bounds1.top >= bounds2.top\n",
    "        and bounds1.bottom <= bounds2.bottom\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The bounds of input1 must be equal to or larger than those of input2.\"\n",
    "        )\n",
    "\n",
    "    # Create masks for valid data\n",
    "    valid_mask = (input1 != nodata1) & (input2 != nodata2)\n",
    "\n",
    "    # Now only compare where both rasters have valid data\n",
    "    output = np.full(input1.shape, 255, dtype=np.uint8)  # initialize with nodata (255)\n",
    "    output[valid_mask] = ((input1 == 1) & (input2 == 0))[valid_mask].astype(np.uint8)\n",
    "\n",
    "    # Update the profile for the output raster\n",
    "    profile.update(dtype=rasterio.uint8, compress=\"deflate\", nodata=255)\n",
    "\n",
    "    # Write the output raster\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(output, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def process_forest_loss(input1_path, input2_path, output_path):\n",
    "    # Open the input rasters\n",
    "    with rasterio.open(input1_path) as src1:\n",
    "        input1 = src1.read(1)\n",
    "        bounds1 = src1.bounds\n",
    "        profile = src1.profile\n",
    "        nodata1 = src1.nodata\n",
    "\n",
    "    with rasterio.open(input2_path) as src2:\n",
    "        input2 = src2.read(1)\n",
    "        bounds2 = src2.bounds\n",
    "        nodata2 = src2.nodata\n",
    "\n",
    "    # Check if the bounds of input1 are equal to or larger than those of input2\n",
    "    if not (\n",
    "        bounds1.left <= bounds2.left\n",
    "        and bounds1.right >= bounds2.right\n",
    "        and bounds1.top >= bounds2.top\n",
    "        and bounds1.bottom <= bounds2.bottom\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The bounds of input1 must be equal to or larger than those of input2.\"\n",
    "        )\n",
    "\n",
    "    # Create masks for valid data\n",
    "    valid_mask = (input1 != nodata1) & (input2 != nodata2)\n",
    "\n",
    "    # Initialize output with nodata (255)\n",
    "    output = np.full(input1.shape, 255, dtype=np.uint8)\n",
    "\n",
    "    # Set values based on conditions:\n",
    "    # 1 where input1 == 1 and input2 == 0\n",
    "    # 0 where input1 == 1 and input2 == 1\n",
    "    # nodata (255) for all other cases\n",
    "\n",
    "    # Create condition for 1s: input1 == 1 AND input2 == 0\n",
    "    condition_1 = (input1 == 1) & (input2 == 0)\n",
    "\n",
    "    # Create condition for 0s: input1 == 1 AND input2 == 1\n",
    "    condition_0 = (input1 == 1) & (input2 == 1)\n",
    "\n",
    "    # Apply conditions only where both inputs are valid\n",
    "    output[valid_mask & condition_1] = 0\n",
    "    output[valid_mask & condition_0] = 1\n",
    "\n",
    "    # Update the profile for the output raster\n",
    "    profile.update(dtype=rasterio.uint8, compress=\"deflate\", nodata=255)\n",
    "\n",
    "    # Write the output raster\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(output, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d51b3a-b419-4e53-ac0b-0607162c7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# List all raster files in the input folder\n",
    "forest_raster_files = list_files_by_extension(processed_data_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "# Define the words to filter by\n",
    "filter_words = [\"forest\", \"reprojected\", forest_source]\n",
    "\n",
    "# Define the words to exclude from the filtered files\n",
    "exclude_words = [\"distance\", \"edge\"]\n",
    "\n",
    "# Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "filtered_raster_files = [\n",
    "    file\n",
    "    for file in forest_raster_files\n",
    "    if all(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    and not any(\n",
    "        exclude_word in os.path.basename(file).lower() for exclude_word in exclude_words\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Function to extract the year from a filename\n",
    "def extract_year(filename):\n",
    "    match = re.search(r\"\\d{4}\", os.path.basename(filename))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "\n",
    "# Sort the filtered raster files based on the extracted year in ascending order\n",
    "sorted_raster_files = sorted(filtered_raster_files, key=extract_year)\n",
    "\n",
    "sorted_raster_files  # Print the sorted list to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e72fa4-0bbb-4297-8148-c0cfa204960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_filename(i1, i2):\n",
    "    # Extract the base names from the input file paths\n",
    "    base_name_i1 = i1.split(\"/\")[-1].split(\".\")[0]\n",
    "    base_name_i2 = i2.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Find the common prefix up to the year\n",
    "    def extract_common_prefix(base_name):\n",
    "        common_prefix = \"\"\n",
    "        for word in base_name.split(\"_\"):\n",
    "            if (\n",
    "                word.isdigit() and len(word) == 4\n",
    "            ):  # Check if the word is a four-digit year\n",
    "                break\n",
    "            common_prefix += word + \"_\"\n",
    "        return common_prefix.strip(\"_\")\n",
    "\n",
    "    common_prefix = extract_common_prefix(base_name_i1)\n",
    "\n",
    "    # Extract the years from the base names and ensure they are four digits\n",
    "    def extract_year(base_name):\n",
    "        year = next(\n",
    "            (\n",
    "                word\n",
    "                for word in base_name.split(\"_\")\n",
    "                if word.isdigit() and len(word) == 4\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if not year:\n",
    "            raise ValueError(\n",
    "                f\"Year could not be extracted or is not four digits: {year}\"\n",
    "            )\n",
    "        return year\n",
    "\n",
    "    year_i1 = extract_year(base_name_i1)\n",
    "    year_i2 = extract_year(base_name_i2)\n",
    "\n",
    "    # Construct the output file name based on the input file names\n",
    "    prefix = f\"{common_prefix}_loss\"\n",
    "    suffix = f\"{year_i1}_{year_i2}.tif\"\n",
    "\n",
    "    # Combine the directory path with the new file name\n",
    "    dir_path = \"/\".join(i1.split(\"/\")[:-1])\n",
    "    output_filename = f\"{dir_path}/{prefix}_{suffix}\"\n",
    "\n",
    "    return output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999dc5d1-f1fb-4c75-becf-427c6656f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss1_filename = generate_output_filename(\n",
    "    sorted_raster_files[0], sorted_raster_files[1]\n",
    ")\n",
    "process_forest_loss(\n",
    "    sorted_raster_files[0], sorted_raster_files[1], forest_loss1_filename\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a3710-d134-41c2-a053-09360a2d3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss2_filename = generate_output_filename(\n",
    "    sorted_raster_files[0], sorted_raster_files[2]\n",
    ")\n",
    "process_forest_loss(\n",
    "    sorted_raster_files[0], sorted_raster_files[2], forest_loss2_filename\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b87c53-e081-467e-a9dc-97e3836926e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss3_filename = generate_output_filename(\n",
    "    sorted_raster_files[1], sorted_raster_files[2]\n",
    ")\n",
    "process_forest_loss(\n",
    "    sorted_raster_files[1], sorted_raster_files[2], forest_loss3_filename\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2719d-7f86-4695-a28d-21cf9b566ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def generate_deforestation_raster(\n",
    "    raster1_path, raster2_path, raster3_path, output_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a deforestation raster from three input rasters.\n",
    "\n",
    "    Parameters:\n",
    "    - raster1_path: Path to the first raster file (period 1).\n",
    "    - raster2_path: Path to the second raster file (period 2).\n",
    "    - raster3_path: Path to the third raster file (period 3).\n",
    "    - output_path: Path to save the output raster file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input rasters\n",
    "    with (\n",
    "        rasterio.open(raster1_path) as src1,\n",
    "        rasterio.open(raster2_path) as src2,\n",
    "        rasterio.open(raster3_path) as src3,\n",
    "    ):\n",
    "        # Read the data into numpy arrays\n",
    "        raster1 = src1.read(1)\n",
    "        raster2 = src2.read(1)\n",
    "        raster3 = src3.read(1)\n",
    "\n",
    "        # Create an output array initialized with NoData value (0)\n",
    "        output_raster = np.zeros_like(raster1, dtype=np.uint8)\n",
    "\n",
    "        # Set the values based on deforestation periods\n",
    "        output_raster[(raster1 == 1) & (raster2 == 0)] = (\n",
    "            1  # Deforestation in period 1-2\n",
    "        )\n",
    "        output_raster[(raster2 == 1) & (raster3 == 0)] = (\n",
    "            2  # Deforestation in period 2-3\n",
    "        )\n",
    "        # Set the remaining forest value only where no deforestation has been marked\n",
    "        output_raster[(output_raster == 0) & (raster3 == 1)] = (\n",
    "            3  # Remaining forest in period 3\n",
    "        )\n",
    "\n",
    "    # Define the metadata for the output raster\n",
    "    meta = src1.meta\n",
    "    meta.update({\"count\": 1, \"dtype\": np.uint8, \"nodata\": 0, \"compress\": \"deflate\"})\n",
    "\n",
    "    # Write the output raster to a file\n",
    "    with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "        dst.write(output_raster, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6965e-2a4d-426a-8a0f-e5c372ba73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_filename2(i1, i2, i3):\n",
    "    # Extract the base names from the input file paths\n",
    "    base_name_i1 = i1.split(\"/\")[-1].split(\".\")[0]\n",
    "    base_name_i2 = i2.split(\"/\")[-1].split(\".\")[0]\n",
    "    base_name_i3 = i3.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Find the common prefix up to the year\n",
    "    def extract_common_prefix(base_name):\n",
    "        common_prefix = \"\"\n",
    "        for word in base_name.split(\"_\"):\n",
    "            if (\n",
    "                word.isdigit() and len(word) == 4\n",
    "            ):  # Check if the word is a four-digit year\n",
    "                break\n",
    "            common_prefix += word + \"_\"\n",
    "        return common_prefix.strip(\"_\")\n",
    "\n",
    "    common_prefix = extract_common_prefix(base_name_i1)\n",
    "\n",
    "    # Extract the years from the base names and ensure they are four digits\n",
    "    def extract_year(base_name):\n",
    "        year = next(\n",
    "            (\n",
    "                word\n",
    "                for word in base_name.split(\"_\")\n",
    "                if word.isdigit() and len(word) == 4\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if not year:\n",
    "            raise ValueError(\n",
    "                f\"Year could not be extracted or is not four digits: {year}\"\n",
    "            )\n",
    "        return year\n",
    "\n",
    "    year_i1 = extract_year(base_name_i1)\n",
    "    year_i2 = extract_year(base_name_i2)\n",
    "    year_i3 = extract_year(base_name_i3)\n",
    "\n",
    "    # Construct the output file name based on the input file names\n",
    "    prefix = f\"{common_prefix}_loss\"\n",
    "    suffix = f\"{year_i1}_{year_i2}_{year_i3}.tif\"\n",
    "\n",
    "    # Combine the directory path with the new file name\n",
    "    dir_path = \"/\".join(i1.split(\"/\")[:-1])\n",
    "    output_filename = f\"{dir_path}/{prefix}_{suffix}\"\n",
    "\n",
    "    return output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401a364-f3ce-4292-a069-10885a77180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_forest_loss_filename = generate_output_filename2(\n",
    "    sorted_raster_files[0], sorted_raster_files[1], sorted_raster_files[2]\n",
    ")\n",
    "total_forest_loss = generate_deforestation_raster(\n",
    "    sorted_raster_files[0],\n",
    "    sorted_raster_files[1],\n",
    "    sorted_raster_files[2],\n",
    "    total_forest_loss_filename,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e91ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deforisk-jupyter-nb (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
