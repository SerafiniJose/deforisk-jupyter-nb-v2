{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb9c20-89fb-4287-ab3e-2ce78cfe204d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup gdal and lib paths\n",
    "#import os\n",
    "\n",
    "#os.environ[\"PROJ_LIB\"] = \"/usr/share/proj\"\n",
    "#os.environ[\"GDAL_DATA\"] = \"/usr/share/gdal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDAL optimizations\n",
    "# import multiprocessing\n",
    "# import os\n",
    "\n",
    "# cpu_count: int = multiprocessing.cpu_count()\n",
    "# num_cores: int = max(1, cpu_count - 1)\n",
    "# os.environ[\"GDAL_NUM_THREADS\"] = f\"{num_cores}\"\n",
    "# os.environ[\"GDAL_CACHEMAX\"] = \"1024\"\n",
    "\n",
    "# import psutil\n",
    "# memory_gb = psutil.virtual_memory().total / (1024**3)\n",
    "# print(psutil.virtual_memory().total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7482e31-e641-481d-b7ce-37c1ae376fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from fiona.transform import transform_geom\n",
    "from osgeo import gdal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root to path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from component.script.utilities.file_filter import (\n",
    "    list_files_by_extension,\n",
    "    filter_files_by_keywords,\n",
    ")\n",
    "from component.script.xarray.dask_reproject_rio import (\n",
    "    reproject_raster_rio_with_dask,\n",
    ")\n",
    "from component.script.xarray.dask_distance_xarray_spatial import (\n",
    "    raster_proximity_with_dask,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357db97-b9e1-480e-b80d-5427b18cbae5",
   "metadata": {},
   "source": [
    "## Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05852c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_epsg_code = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc599b88",
   "metadata": {},
   "source": [
    "## Describe variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc31df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_source = \"gfc\"\n",
    "tree_cover_threshold = 10\n",
    "years: list[int] = [2015, 2020, 2024]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede069ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_forest_loss = True\n",
    "calculate_forest_loss_stack = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39640a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_binary = [\"aoi\"]\n",
    "vector_unique_values = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57214f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_categorical_variables = [\"towns\", \"rivers\", \"roads\", \"pa\", forest_source]\n",
    "raster_continuos_variables = [\"altitude\", \"slope\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_edge = [\"forest\"]\n",
    "raster_distance = [\"rivers\", \"roads\", \"town\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4087f",
   "metadata": {},
   "source": [
    "## Connect folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder: Path = Path.cwd().parent\n",
    "downloads_folder: Path = root_folder / \"data\"\n",
    "downloads_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ee2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = downloads_folder / project_name\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "data_raw_folder = project_folder / \"data_raw\"\n",
    "data_raw_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_data_folder = project_folder / \"data\"\n",
    "processed_data_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ff094-9fb0-49cf-ad50-35174df271f8",
   "metadata": {},
   "source": [
    "## Calculate epsg code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal, Union\n",
    "\n",
    "import rioxarray\n",
    "\n",
    "\n",
    "def calculate_utm_rioxarray(\n",
    "    input_tif_file_path: str | Path,\n",
    "    output_mode: Literal[\"str\", \"int\"] = \"str\",\n",
    ") -> str | int | None:\n",
    "    \"\"\"\n",
    "    Estimate the UTM CRS of a GeoTIFF file using rioxarray.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_tif_file_path : str | Path\n",
    "        The path to the raster file.\n",
    "    output_mode : Literal[\"str\", \"int\"], default=\"str\"\n",
    "        How to return the CRS.  ``\"str\"`` returns an EPSG string (e.g.,\n",
    "        ``EPSG:32633``); ``\"int\"`` returns the numeric EPSG code.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str | int | None\n",
    "        The CRS representation or ``None`` if it could not be estimated.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If the file does not exist.\n",
    "    ValueError\n",
    "        If an unsupported `output_mode` is supplied.\n",
    "    RuntimeError\n",
    "        If rioxarray fails to open the raster.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> calculate_utm_rioxarray(\"sample.tif\")\n",
    "    'EPSG:32633'\n",
    "    >>> calculate_utm_rioxarray(\"sample.tif\", output_mode=\"int\")\n",
    "    32633\n",
    "    \"\"\"\n",
    "    # Validate path\n",
    "    path = Path(input_tif_file_path)\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(f\"Raster file {input_tif_file_path!r} does not exist\")\n",
    "\n",
    "    try:\n",
    "        raster = rioxarray.open_rasterio(path, chunks=\"auto\", cache=False, lock=False)\n",
    "    except Exception as exc:  # pragma: no cover\n",
    "        raise RuntimeError(f\"Failed to open raster {path!s}\") from exc\n",
    "\n",
    "    try:\n",
    "        utm_crs = raster.rio.estimate_utm_crs()\n",
    "        if utm_crs is None:\n",
    "            return None\n",
    "\n",
    "        if output_mode == \"str\":\n",
    "            return utm_crs.to_string()\n",
    "        elif output_mode == \"int\":\n",
    "            epsg_code = utm_crs.to_epsg()  # may still be None\n",
    "            return epsg_code\n",
    "        else:  # pragma: no cover\n",
    "            raise ValueError(f\"output_mode must be 'str' or 'int', got {output_mode!r}\")\n",
    "    finally:\n",
    "        # Ensure the dataset is closed to free resources\n",
    "        raster.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d33817-9be8-4070-9786-23b777fab4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "\n",
    "def get_centroid(shapefile_path):\n",
    "    \"\"\"\n",
    "    Get the centroid of the first feature in a shapefile using Shapely and Fiona.\n",
    "\n",
    "    Parameters:\n",
    "        shapefile_path (str): Path to the input shapefile.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the latitude and longitude of the centroid.\n",
    "    \"\"\"\n",
    "    # Open the shapefile\n",
    "    with fiona.open(shapefile_path, \"r\") as shapefile:\n",
    "        # Get the first feature\n",
    "        first_feature = next(iter(shapefile))\n",
    "\n",
    "        # Convert the feature geometry to a Shapely geometry object\n",
    "        geom = shape(first_feature[\"geometry\"])\n",
    "\n",
    "        # Calculate the centroid\n",
    "        centroid = geom.centroid\n",
    "\n",
    "        # Get the coordinates of the centroid\n",
    "        longitude, latitude = centroid.x, centroid.y\n",
    "\n",
    "    return (longitude, latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b9cbf-793c-4dc5-8327-e3ff02fdff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utm_proj_str_from_lat_lon(lon, lat):\n",
    "    \"\"\"\n",
    "    Given a longitude, latitude in WGS84, return the EPSG code as a string\n",
    "    for the corresponding UTM or UPS projection.\n",
    "\n",
    "    - UTM: EPSG:326xx (Northern) or EPSG:327xx (Southern)\n",
    "    - UPS: EPSG:5041 (North, >84°N), EPSG:5042 (South, <–80°S)\n",
    "\n",
    "    Handles special cases for Norway and Svalbard.\n",
    "    \"\"\"\n",
    "    # UPS zones for polar regions\n",
    "    if lat >= 84:\n",
    "        return \"EPSG:5041\"  # UPS North\n",
    "    elif lat <= -80:\n",
    "        return \"EPSG:5042\"  # UPS South\n",
    "\n",
    "    # Special cases for Norway and Svalbard\n",
    "    if lat > 55 and lat < 64 and lon > 2 and lon < 6:\n",
    "        zone_number = 32\n",
    "    elif lat > 71 and lon >= 6 and lon < 9:\n",
    "        zone_number = 31\n",
    "    elif lat > 71 and ((lon >= 9 and lon < 12) or (lon >= 18 and lon < 21)):\n",
    "        zone_number = 33\n",
    "    elif lat > 71 and ((lon >= 21 and lon < 24) or (lon >= 30 and lon < 33)):\n",
    "        zone_number = 35\n",
    "    else:\n",
    "        zone_number = int((lon + 180) / 6) + 1\n",
    "\n",
    "    if lat >= 0:\n",
    "        epsg_code = 32600 + zone_number  # Northern Hemisphere\n",
    "    else:\n",
    "        epsg_code = 32700 + zone_number  # Southern Hemisphere\n",
    "\n",
    "    return f\"EPSG:{epsg_code}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad62ce-2157-4d26-a3a8-b7be8149b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_centroid = get_centroid(str(data_raw_folder) + \"/\" + project_name + \"_aoi.shp\")\n",
    "calculated_epsg = get_utm_proj_str_from_lat_lon(aoi_centroid[0], aoi_centroid[1])\n",
    "calculated_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc11aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_epsg = calculate_utm_rioxarray(\n",
    "    str(data_raw_folder) + \"/\" + project_name + \"_subj.tif\"\n",
    ")\n",
    "calculated_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_defined_epsg_code is None:\n",
    "    epsg_code = calculated_epsg\n",
    "elif user_defined_epsg_code is not None:\n",
    "    epsg_code = user_defined_epsg_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f4563-f021-461a-87a8-561e28473b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae0c73",
   "metadata": {},
   "source": [
    "## Define base raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base raster to allign all the others to\n",
    "base_file_raster = str(data_raw_folder) + \"/\" + project_name + \"_subj.tif\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa982f6a",
   "metadata": {},
   "source": [
    "## Reproject Base file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28990986-29ce-4202-9eb3-689c3238f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def reproject_raster_gdal_warp(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    target_epsg: str,\n",
    "    resolution: int | float = 30,\n",
    "    resampling_method: str = \"near\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reprojects a raster file to a specified EPSG code using GDAL and saves it with DEFLATE compression.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input raster file.\n",
    "    output_file (str): The path where the reprojected raster file will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input dataset\n",
    "    dataset = gdal.Open(input_file)\n",
    "    if not dataset:\n",
    "        raise FileNotFoundError(f\"Input file {input_file} not found.\")\n",
    "\n",
    "    # Get projection and geotransform from the original raster\n",
    "    src_proj = dataset.GetProjection()\n",
    "\n",
    "    # Callback\n",
    "    param = gdal.WarpOptions(\n",
    "        warpOptions=[\"overwrite\"],\n",
    "        srcSRS=src_proj,\n",
    "        dstSRS=target_epsg,\n",
    "        targetAlignedPixels=True,\n",
    "        resampleAlg=resampling_method,\n",
    "        xRes=resolution,\n",
    "        yRes=resolution,\n",
    "        multithread=True,\n",
    "        creationOptions=[\n",
    "            \"COMPRESS=DEFLATE\",\n",
    "            \"PREDICTOR=2\",\n",
    "            \"BIGTIFF=YES\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Perform reprojection\n",
    "    gdal.Warp(output_file, input_file, format=\"GTiff\", options=param)\n",
    "\n",
    "    # Close datasets\n",
    "    dataset = None\n",
    "    out_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eabe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_raster = Path(base_file_raster)\n",
    "base_name = base_file_raster.stem\n",
    "reprojected_file_path = Path(processed_data_folder) / f\"{base_name}_reprojected.tif\"\n",
    "\n",
    "reprojected_base_file = reproject_raster_gdal_warp(\n",
    "    base_file_raster,\n",
    "    reprojected_file_path,\n",
    "    epsg_code,\n",
    "    resolution=30.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43321989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import odc.geo.xr\n",
    "\n",
    "\n",
    "def get_geobox(tif_file: str = None):\n",
    "    raster_array = rioxarray.open_rasterio(\n",
    "        tif_file,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    )\n",
    "    return raster_array.odc.geobox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_geobox = get_geobox(reprojected_file_path)\n",
    "base_geobox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d8216",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate Forest Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34865b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def process_forest_loss(input1_path, input2_path, output_path):\n",
    "    # Open the input rasters\n",
    "    with rasterio.open(input1_path) as src1:\n",
    "        input1 = src1.read(1)\n",
    "        bounds1 = src1.bounds\n",
    "        profile = src1.profile\n",
    "        nodata1 = src1.nodata\n",
    "\n",
    "    with rasterio.open(input2_path) as src2:\n",
    "        input2 = src2.read(1)\n",
    "        bounds2 = src2.bounds\n",
    "        nodata2 = src2.nodata\n",
    "\n",
    "    # Check if the bounds of input1 are equal to or larger than those of input2\n",
    "    if not (\n",
    "        bounds1.left <= bounds2.left\n",
    "        and bounds1.right >= bounds2.right\n",
    "        and bounds1.top >= bounds2.top\n",
    "        and bounds1.bottom <= bounds2.bottom\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The bounds of input1 must be equal to or larger than those of input2.\"\n",
    "        )\n",
    "\n",
    "    # Create masks for valid data\n",
    "    valid_mask = (input1 != nodata1) & (input2 != nodata2)\n",
    "\n",
    "    # Initialize output with nodata (255)\n",
    "    output = np.full(input1.shape, 255, dtype=np.uint8)\n",
    "\n",
    "    # Set values based on conditions:\n",
    "    # 1 where input1 == 1 and input2 == 0\n",
    "    # 0 where input1 == 1 and input2 == 1\n",
    "    # nodata (255) for all other cases\n",
    "\n",
    "    # Create condition for 1s: input1 == 1 AND input2 == 0\n",
    "    condition_1 = (input1 == 1) & (input2 == 0)\n",
    "\n",
    "    # Create condition for 0s: input1 == 1 AND input2 == 1\n",
    "    condition_0 = (input1 == 1) & (input2 == 1)\n",
    "\n",
    "    # Apply conditions only where both inputs are valid\n",
    "    output[valid_mask & condition_1] = 0\n",
    "    output[valid_mask & condition_0] = 1\n",
    "\n",
    "    # Update the profile for the output raster\n",
    "    profile.update(dtype=rasterio.uint8, compress=\"deflate\", nodata=255)\n",
    "\n",
    "    # Write the output raster\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(output, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706ae76-2a0d-45bf-b4d1-88d8fabf2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_forest_loss_xarray(input1_path, input2_path, output_path):\n",
    "    # Open the input rasters\n",
    "    input1 = rioxarray.open_rasterio(\n",
    "        input1_path,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    ).squeeze()\n",
    "    input2 = rioxarray.open_rasterio(\n",
    "        input2_path,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    ).squeeze()\n",
    "\n",
    "    # Check bounds properly - extract bounds tuple values\n",
    "    bounds1 = input1.rio.bounds()\n",
    "    bounds2 = input2.rio.bounds()\n",
    "\n",
    "    if not (\n",
    "        bounds1[0] <= bounds2[0]  # left\n",
    "        and bounds1[2] >= bounds2[2]  # right\n",
    "        and bounds1[3] >= bounds2[3]  # top\n",
    "        and bounds1[1] <= bounds2[1]  # bottom\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The bounds of input1 must be equal to or larger than those of input2.\"\n",
    "        )\n",
    "\n",
    "    # Create masks for valid data\n",
    "    nodata1 = input1.rio.nodata\n",
    "    nodata2 = input2.rio.nodata\n",
    "    valid_mask = (input1 != nodata1) & (input2 != nodata2)\n",
    "\n",
    "    # Create output based on conditions using xarray operations\n",
    "    output = xr.where(\n",
    "        valid_mask & (input1 == 1) & (input2 == 0),\n",
    "        0,  # condition 0: input1 == 1 and input2 == 0\n",
    "        xr.where(\n",
    "            valid_mask & (input1 == 1) & (input2 == 1),\n",
    "            1,  # condition 1: input1 == 1 and input2 == 1\n",
    "            255,  # nodata for all other cases\n",
    "        ),\n",
    "    ).astype(\"uint8\")\n",
    "\n",
    "    # Set proper metadata\n",
    "    output.rio.write_nodata(255, inplace=True)\n",
    "    output.rio.write_crs(input1.rio.crs, inplace=True)\n",
    "    output.rio.write_transform(input1.rio.transform(), inplace=True)\n",
    "\n",
    "    output.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceba140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# List all raster files in the input folder\n",
    "forest_raster_files = list_files_by_extension(data_raw_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "\n",
    "# Define the words to filter by\n",
    "if tree_cover_threshold:\n",
    "    filter_words = [\"forest\", forest_source, str(tree_cover_threshold)]\n",
    "elif tree_cover_threshold is None:\n",
    "    filter_words = [\"forest\", forest_source]\n",
    "\n",
    "filtered_raster_files = filter_files_by_keywords(\n",
    "    forest_raster_files,\n",
    "    filter_words,\n",
    "    False,\n",
    "    [\"loss\"],\n",
    "    True,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract the year from a filename\n",
    "def extract_year(filename):\n",
    "    match = re.search(r\"\\d{4}\", os.path.basename(filename))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "\n",
    "# Sort the filtered raster files based on the extracted year in ascending order\n",
    "sorted_raster_files = sorted(filtered_raster_files, key=extract_year)\n",
    "\n",
    "sorted_raster_files  # Print the sorted list to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8cdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def generate_output_filename_loss(i1: Path, i2: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Generate an output filename based on two input file paths.\n",
    "\n",
    "    Args:\n",
    "        i1: First input file path\n",
    "        i2: Second input file path\n",
    "\n",
    "    Returns:\n",
    "        Path object for the generated output filename\n",
    "    \"\"\"\n",
    "    # Extract the base names from the input file paths\n",
    "    base_name_i1 = i1.stem  # Gets filename without extension\n",
    "    base_name_i2 = i2.stem  # Gets filename without extension\n",
    "\n",
    "    # Find the common prefix up to the year\n",
    "    def extract_common_prefix(base_name):\n",
    "        common_prefix = \"\"\n",
    "        for word in base_name.split(\"_\"):\n",
    "            if (\n",
    "                word.isdigit() and len(word) == 4\n",
    "            ):  # Check if the word is a four-digit year\n",
    "                break\n",
    "            common_prefix += word + \"_\"\n",
    "        return common_prefix.strip(\"_\")\n",
    "\n",
    "    common_prefix = extract_common_prefix(base_name_i1)\n",
    "\n",
    "    # Extract the years from the base names and ensure they are four digits\n",
    "    def extract_year(base_name):\n",
    "        year = next(\n",
    "            (\n",
    "                word\n",
    "                for word in base_name.split(\"_\")\n",
    "                if word.isdigit() and len(word) == 4\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if not year:\n",
    "            raise ValueError(\n",
    "                f\"Year could not be extracted or is not four digits: {base_name}\"\n",
    "            )\n",
    "        return year\n",
    "\n",
    "    year_i1 = extract_year(base_name_i1)\n",
    "    year_i2 = extract_year(base_name_i2)\n",
    "\n",
    "    # Construct the output file name based on the input file names\n",
    "    prefix = f\"{common_prefix}_loss\"\n",
    "    suffix = f\"{year_i1}_{year_i2}.tif\"\n",
    "\n",
    "    # Combine the directory path with the new file name\n",
    "    output_filename = i1.parent / f\"{prefix}_{suffix}\"\n",
    "\n",
    "    return output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ed71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_forest_loss is True:\n",
    "    forest_loss1_filename = generate_output_filename_loss(\n",
    "        sorted_raster_files[0], sorted_raster_files[1]\n",
    "    )\n",
    "    if not Path(forest_loss1_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[0], sorted_raster_files[1], forest_loss1_filename\n",
    "        )\n",
    "    forest_loss2_filename = generate_output_filename_loss(\n",
    "        sorted_raster_files[0], sorted_raster_files[2]\n",
    "    )\n",
    "    if not Path(forest_loss2_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[0], sorted_raster_files[2], forest_loss2_filename\n",
    "        )\n",
    "    forest_loss3_filename = generate_output_filename_loss(\n",
    "        sorted_raster_files[1], sorted_raster_files[2]\n",
    "    )\n",
    "    if not Path(forest_loss3_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[1], sorted_raster_files[2], forest_loss3_filename\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def generate_deforestation_raster(\n",
    "    raster1_path, raster2_path, raster3_path, output_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a deforestation raster from three input rasters.\n",
    "\n",
    "    Parameters:\n",
    "    - raster1_path: Path to the first raster file (period 1).\n",
    "    - raster2_path: Path to the second raster file (period 2).\n",
    "    - raster3_path: Path to the third raster file (period 3).\n",
    "    - output_path: Path to save the output raster file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input rasters\n",
    "    with (\n",
    "        rasterio.open(raster1_path) as src1,\n",
    "        rasterio.open(raster2_path) as src2,\n",
    "        rasterio.open(raster3_path) as src3,\n",
    "    ):\n",
    "        # Read the data into numpy arrays\n",
    "        raster1 = src1.read(1)\n",
    "        raster2 = src2.read(1)\n",
    "        raster3 = src3.read(1)\n",
    "\n",
    "        # Create an output array initialized with NoData value (0)\n",
    "        output_raster = np.zeros_like(raster1, dtype=np.uint8)\n",
    "\n",
    "        # Set the values based on deforestation periods\n",
    "        output_raster[(raster1 == 1) & (raster2 == 0)] = (\n",
    "            1  # Deforestation in period 1-2\n",
    "        )\n",
    "        output_raster[(raster2 == 1) & (raster3 == 0)] = (\n",
    "            2  # Deforestation in period 2-3\n",
    "        )\n",
    "        # Set the remaining forest value only where no deforestation has been marked\n",
    "        output_raster[(output_raster == 0) & (raster3 == 1)] = (\n",
    "            3  # Remaining forest in period 3\n",
    "        )\n",
    "\n",
    "    # Define the metadata for the output raster\n",
    "    meta = src1.meta\n",
    "    meta.update({\"count\": 1, \"dtype\": np.uint8, \"nodata\": 0, \"compress\": \"deflate\"})\n",
    "\n",
    "    # Write the output raster to a file\n",
    "    with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "        dst.write(output_raster, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def generate_output_filename_stack(i1: Path, i2: Path, i3: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Generate an output filename based on three input file paths.\n",
    "\n",
    "    Args:\n",
    "        i1: First input file path\n",
    "        i2: Second input file path\n",
    "        i3: Third input file path\n",
    "\n",
    "    Returns:\n",
    "        Path object for the generated output filename\n",
    "    \"\"\"\n",
    "    # Extract the base names from the input file paths\n",
    "    base_name_i1 = i1.stem  # Gets filename without extension\n",
    "    base_name_i2 = i2.stem  # Gets filename without extension\n",
    "    base_name_i3 = i3.stem  # Gets filename without extension\n",
    "\n",
    "    # Find the common prefix up to the year\n",
    "    def extract_common_prefix(base_name):\n",
    "        common_prefix = \"\"\n",
    "        for word in base_name.split(\"_\"):\n",
    "            if (\n",
    "                word.isdigit() and len(word) == 4\n",
    "            ):  # Check if the word is a four-digit year\n",
    "                break\n",
    "            common_prefix += word + \"_\"\n",
    "        return common_prefix.strip(\"_\")\n",
    "\n",
    "    common_prefix = extract_common_prefix(base_name_i1)\n",
    "\n",
    "    # Extract the years from the base names and ensure they are four digits\n",
    "    def extract_year(base_name):\n",
    "        year = next(\n",
    "            (\n",
    "                word\n",
    "                for word in base_name.split(\"_\")\n",
    "                if word.isdigit() and len(word) == 4\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if not year:\n",
    "            raise ValueError(\n",
    "                f\"Year could not be extracted or is not four digits: {base_name}\"\n",
    "            )\n",
    "        return year\n",
    "\n",
    "    year_i1 = extract_year(base_name_i1)\n",
    "    year_i2 = extract_year(base_name_i2)\n",
    "    year_i3 = extract_year(base_name_i3)\n",
    "\n",
    "    # Construct the output file name based on the input file names\n",
    "    prefix = f\"{common_prefix}_loss\"\n",
    "    suffix = f\"{year_i1}_{year_i2}_{year_i3}.tif\"\n",
    "\n",
    "    # Combine the directory path with the new file name\n",
    "    output_filename = i1.parent / f\"{prefix}_{suffix}\"\n",
    "\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create example paths\n",
    "    file1 = Path(\"/path/to/data_2020_analysis.txt\")\n",
    "    file2 = Path(\"/path/to/data_2021_results.txt\")\n",
    "    file3 = Path(\"/path/to/data_2022_summary.txt\")\n",
    "\n",
    "    # Generate output filename\n",
    "    output_path = generate_output_filename_stack(file1, file2, file3)\n",
    "    print(f\"Generated output path: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d241db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_forest_loss_stack is True:\n",
    "    total_forest_loss_filename = generate_output_filename_stack(\n",
    "        sorted_raster_files[0], sorted_raster_files[1], sorted_raster_files[2]\n",
    "    )\n",
    "    if not Path(total_forest_loss_filename).exists():\n",
    "        total_forest_loss = generate_deforestation_raster(\n",
    "            sorted_raster_files[0],\n",
    "            sorted_raster_files[1],\n",
    "            sorted_raster_files[2],\n",
    "            total_forest_loss_filename,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9516c",
   "metadata": {},
   "source": [
    "## Reproject and Rasterize Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e20fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_rasterize(\n",
    "    shapefile_path: str = None,\n",
    "    geobox=None,\n",
    "    crs=None,\n",
    "    output_path: str = None,\n",
    "    mode: str = \"binary\",\n",
    "    **rasterio_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Rasterizes a vector shapefile into a raster array.\n",
    "\n",
    "    This function provides unified functionality for both binary and unique ID rasterization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shapefile_path : str\n",
    "        Path to the input shapefile containing vector data.\n",
    "    geobox : odc.geo.geobox.GeoBox\n",
    "        The spatial template defining the shape, coordinates, dimensions, and transform\n",
    "        of the output raster.\n",
    "    crs : str or CRS object, optional\n",
    "        If ``geobox``'s coordinate reference system (CRS) cannot be\n",
    "        determined, provide a CRS using this parameter.\n",
    "        (e.g. 'EPSG:3577').\n",
    "    output_path : string, optional\n",
    "        Provide an optional string file path to export the rasterized\n",
    "        data as a GeoTIFF file.\n",
    "    mode : str, optional\n",
    "        Rasterization mode: 'binary' or 'unique'.\n",
    "        - 'binary': Creates a boolean raster with 1s and 0s (default)\n",
    "        - 'unique': Creates a raster with unique integer IDs for each feature\n",
    "    **rasterio_kwargs :\n",
    "        A set of keyword arguments to ``rasterio.features.rasterize``.\n",
    "        Can include: 'all_touched', 'merge_alg', 'dtype'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    da_rasterized : xarray.DataArray\n",
    "        The rasterized vector data.\n",
    "    \"\"\"\n",
    "\n",
    "    import geopandas as gpd\n",
    "    import rasterio\n",
    "    import rioxarray\n",
    "    import numpy as np\n",
    "    from odc.geo import xr\n",
    "\n",
    "    # Read the shapefile\n",
    "    gdf = gpd.read_file(filename=shapefile_path, engine=\"fiona\")\n",
    "\n",
    "    # Reproject vector data to raster's CRS\n",
    "    gdf_reproj = gdf.to_crs(crs=geobox.crs)\n",
    "\n",
    "    # Handle different modes\n",
    "    if mode == \"binary\":\n",
    "        # Binary mode: rasterize into a boolean array with 1s and 0s\n",
    "        shapes = gdf_reproj.geometry\n",
    "        values = [1] * len(gdf_reproj)  # All features set to 1\n",
    "        shapes_and_values = list(zip(shapes, values))\n",
    "\n",
    "    elif mode == \"unique\":\n",
    "        # Unique ID mode: rasterize using unique integer IDs for each feature\n",
    "        shapes = gdf_reproj.geometry\n",
    "        # Create unique integer IDs starting from 1\n",
    "        values = list(range(1, len(gdf_reproj) + 1))\n",
    "        shapes_and_values = list(zip(shapes, values))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be either 'binary' or 'unique'\")\n",
    "\n",
    "    # Rasterize shapes into a numpy array\n",
    "    im = rasterio.features.rasterize(\n",
    "        shapes=shapes_and_values if mode == \"unique\" else shapes,\n",
    "        out_shape=geobox.shape,\n",
    "        transform=geobox.transform,\n",
    "        dtype=\"uint8\",\n",
    "        **rasterio_kwargs,\n",
    "    )\n",
    "\n",
    "    # Convert numpy array to a full xarray.DataArray\n",
    "    # and set array name if supplied\n",
    "    da_rasterized = xr.wrap_xr(im=im, gbox=geobox)\n",
    "\n",
    "    da_rasterized.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "    )\n",
    "\n",
    "    # Explicitly close references – not strictly required but tidy.\n",
    "    del im\n",
    "    del da_rasterized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a727c5-27c3-4728-b40b-16f3d86b30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def reproject_shapefile(input_path: str, output_path: str, target_crs: str,) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Reprojects a shapefile to a target CRS.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to input shapefile\n",
    "        target_crs (str): Target CRS (e.g., \"EPSG:4326\")\n",
    "        output_path (str, optional): Path to save reprojected shapefile. If None, returns GeoDataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Reprojected GeoDataFrame\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(input_path)\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "    if output_path:\n",
    "        gdf.to_file(output_path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb858cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_shp_files(input_folder, output_folder, geobox):\n",
    "    \"\"\"\n",
    "    Process .shp files by generating corresponding .tif filenames and calling rasterize_vectors.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    geobox (int): The EPSG code of the target coordinate reference system.\n",
    "    \"\"\"\n",
    "    shp_files = list_files_by_extension(input_folder, [\".shp\"])\n",
    "\n",
    "    if vector_binary is not None and len(vector_binary) > 0:\n",
    "        shp_files_binary = filter_files_by_keywords(shp_files, vector_binary)\n",
    "\n",
    "        for shp_file in shp_files_binary:\n",
    "            # Extract the base name of the file without extension\n",
    "            base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            # Create the new .tif filename\n",
    "            tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "            tif_path = os.path.join(output_folder, tif_filename)\n",
    "            # Call rasterize_vectors with the original and new filenames\n",
    "            xr_rasterize(\n",
    "                shapefile_path=shp_file,\n",
    "                geobox=geobox,\n",
    "                output_path=tif_path,\n",
    "                mode=\"binary\",\n",
    "            )\n",
    "    if vector_unique_values is not None and len(vector_unique_values) > 0:\n",
    "        shp_files_unique = filter_files_by_keywords(shp_files, vector_unique_values)\n",
    "\n",
    "        for shp_file in shp_files_unique:\n",
    "            # Extract the base name of the file without extension\n",
    "            base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            # Create the new .tif filename\n",
    "            tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "            tif_path = os.path.join(output_folder, tif_filename)\n",
    "            # Call rasterize_vectors with the original and new filenames\n",
    "            xr_rasterize(\n",
    "                shapefile_path=shp_file,\n",
    "                geobox=geobox,\n",
    "                output_path=tif_path,\n",
    "                mode=\"unique\",\n",
    "            )\n",
    "\n",
    "    shp_files_aoi = filter_files_by_keywords(shp_files, [\"aoi\"])\n",
    "\n",
    "    for shp_file in shp_files_aoi:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        vector_filename = f\"{base_name}_reprojected.shp\"\n",
    "        aoi_vector_reprojected = os.path.join(output_folder, vector_filename)\n",
    "        reproject_shapefile(\n",
    "            shp_file,\n",
    "            aoi_vector_reprojected,\n",
    "            geobox.crs.to_epsg(),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterize_shp_files(data_raw_folder, processed_data_folder, base_geobox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eec285-447d-48f4-a75c-79d7657cc413",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reproject Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301e1eb-4f85-4db1-a1bd-fa0b8a8d841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_near(input_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_categorical_variables\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_raster_gdal_warp(\n",
    "            raster_file,\n",
    "            tif_path,\n",
    "            target_epsg,\n",
    "            # resolution=30.0,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_bilinear(input_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_continuos_variables\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_raster_gdal_warp(\n",
    "            raster_file,\n",
    "            tif_path,\n",
    "            target_epsg,\n",
    "            resampling_method=\"bilinear\",\n",
    "            # resolution=30.0,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb682a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_near(data_raw_folder, processed_data_folder, epsg_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3d779-dc25-4656-9867-6cb80311e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_bilinear(data_raw_folder, processed_data_folder, epsg_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5896b-e3cc-4d9d-8ced-723800b4cb79",
   "metadata": {},
   "source": [
    "## Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182749f-474c-49a3-be6d-38bcb66c130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_edge_gdal_no_mask(\n",
    "    input_file,\n",
    "    dist_file,\n",
    "    values=0,\n",
    "    nodata=0,\n",
    "    max_distance_value=4294967295,\n",
    "    input_nodata=True,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Computes the shortest distance to given pixel values in a raster,\n",
    "    while preserving the original nodata mask in the output.\"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    src_ds = gdal.Open(input_file)\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create raster of distance\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=DEFLATE\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(src_ds.GetProjection())\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Use_input_nodata\n",
    "    ui_nodata = \"YES\" if input_nodata else \"NO\"\n",
    "\n",
    "    # Compute distance\n",
    "    val = \"VALUES=\" + str(values)\n",
    "    use_input_nodata = \"USE_INPUT_NODATA=\" + ui_nodata\n",
    "    max_distance = \"MAXDIST=\" + str(max_distance_value)\n",
    "    distance_nodata = \"NODATA=\" + str(nodata)\n",
    "    cb = gdal.TermProgress_nocb if verbose else 0\n",
    "    gdal.ComputeProximity(\n",
    "        srcband,\n",
    "        dstband,\n",
    "        [val, use_input_nodata, max_distance, distance_nodata, \"DISTUNITS=GEO\"],\n",
    "        callback=cb,\n",
    "    )\n",
    "\n",
    "    # Set nodata value\n",
    "    dstband.SetNoDataValue(max_distance_value)\n",
    "\n",
    "    # Flush to disk\n",
    "    dstband.FlushCache()\n",
    "    dst_ds.FlushCache()\n",
    "\n",
    "    # Clean up\n",
    "    srcband = None\n",
    "    dstband = None\n",
    "    del src_ds, dst_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55afe4-d253-4154-9222-925ec1bd4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = [\"forest\", \"reprojected\", forest_source]\n",
    "\n",
    "    # Define the words to exclude from the filtered files\n",
    "    exclude_words = [\"loss\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if all(word in os.path.basename(file).lower() for word in filter_words)\n",
    "        and not any(\n",
    "            exclude_word in os.path.basename(file).lower()\n",
    "            for exclude_word in exclude_words\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_edge.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee1c7c-3c24-44aa-8a9c-e2980627a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_distance\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_distance.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5f41-2836-465c-9321-5291564843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_tif_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f133c-b57a-46dc-a5c9-728d440da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance_tif_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a0422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deforisk-deg",
   "language": "python",
   "name": "deforisk-deg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
