{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93956c07-d9f1-4e3a-ae1b-148aec301334",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas\n",
    "# import pandas as pd\n",
    "# print(pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizations\n",
    "# GDAL optimizations\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "cpu_count: int = mp.cpu_count()\n",
    "num_cores: int = cpu_count - 2\n",
    "os.environ[\"GDAL_NUM_THREADS\"] = f\"{num_cores}\"\n",
    "os.environ[\"GDAL_CACHEMAX\"] = \"1024\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2a25b-11a9-436c-9eff-17ad4003f00c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13a12a-7502-4c76-b490-9880fbf99c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root to path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from component.script.utilities.file_filter import (\n",
    "    list_files_by_extension,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15850cf5-6362-4e08-aef7-f9372ff90576",
   "metadata": {},
   "source": [
    "## Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106736a8-74db-4767-b3c2-f7c398b97aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754abc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_source = \"gfc\"  ##gfc, tmf\n",
    "tree_cover_threshold = 10\n",
    "years = [2015, 2020, 2024]\n",
    "string_years = [str(num) for num in years]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c312be-754e-43c3-b465-40c41963b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "random_seed = 1\n",
    "spatial_cell_size_km = 10\n",
    "adapt = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d8fcd-6d62-4b47-a589-5921a4cc8102",
   "metadata": {},
   "source": [
    "## Connect folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d607a-c906-459f-8039-3a1bb1abd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder: Path = Path.cwd().parent\n",
    "downloads_folder: Path = root_folder / \"data\"\n",
    "downloads_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07074b-2844-460a-98ca-e8c8917c9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = downloads_folder / project_name\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_data_folder = project_folder / \"data\"\n",
    "processed_data_folder.mkdir(parents=True, exist_ok=True)\n",
    "sampling_folder = project_folder / \"far_samples\"\n",
    "sampling_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff58466-9b05-4d17-b733-bcd2c523a01d",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6104aeb-e4cf-45a0-99dd-2d6e248daee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_files(input_files, filter_words, exclude_words=None, include_all=True):\n",
    "    \"\"\"\n",
    "    Filters a list of files based on include and exclude words.\n",
    "    Parameters:\n",
    "        input_files (list): List of file paths to be filtered.\n",
    "        filter_words (list): Words that must be present in the filenames for inclusion.\n",
    "        exclude_words (list, optional): Words that must not be present in the filenames for exclusion. Defaults to None.\n",
    "        include_all (bool, optional): If True, all filter words must be present in the filename. If False, at least one of the filter words must be present. Defaults to False.\n",
    "    Returns:\n",
    "        list: Filtered list of files.\n",
    "    \"\"\"\n",
    "    # Ensure all words are lowercase for case-insensitive comparison\n",
    "    filter_words = [word.lower() for word in filter_words]\n",
    "    exclude_words = [word.lower() for word in (exclude_words or [])]\n",
    "\n",
    "    if include_all:\n",
    "        filtered_files = [\n",
    "            file\n",
    "            for file in input_files\n",
    "            if all(word in Path(file).name.lower() for word in filter_words)\n",
    "            and not any(\n",
    "                exclude_word in Path(file).name.lower()\n",
    "                for exclude_word in exclude_words\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        filtered_files = [\n",
    "            file\n",
    "            for file in input_files\n",
    "            if any(word in Path(file).name.lower() for word in filter_words)\n",
    "            and not any(\n",
    "                exclude_word in Path(file).name.lower()\n",
    "                for exclude_word in exclude_words\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    return filtered_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba919a-3341-442e-924d-ee870327731d",
   "metadata": {},
   "source": [
    "## Select forest cover change file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d17f5-7b11-481e-8cde-a49d0b51d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all raster files in the processed data folder\n",
    "input_raster_files = list_files_by_extension(processed_data_folder, [\".tiff\", \".tif\"])\n",
    "input_raster_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9d584-29bd-436a-a7f1-aa3a9a0e030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_change_file = filter_files(\n",
    "    input_raster_files,\n",
    "    [\"forest\", \"loss\", forest_source] + [str(num) for num in years],\n",
    "    [\"distance\", \"edge\"],\n",
    ")[0]\n",
    "forest_change_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27afa2dd-3ec8-4a09-a13c-dccfb72fad40",
   "metadata": {},
   "source": [
    "## Periods dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2eff92-7905-4f52-b1f2-cc97ef54bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_dict = {\n",
    "    \"period\": \"calibration\",\n",
    "    \"train_period\": \"calibration\",\n",
    "    \"initial_year\": years[0],\n",
    "    \"final_year\": years[1],\n",
    "    \"defor_value\": 1,\n",
    "    \"time_interval\": years[1] - years[0],\n",
    "}\n",
    "validation_dict = {\n",
    "    \"period\": \"validation\",\n",
    "    \"train_period\": \"calibration\",\n",
    "    \"initial_year\": years[1],\n",
    "    \"final_year\": years[2],\n",
    "    \"defor_value\": 1,\n",
    "    \"time_interval\": years[2] - years[1],\n",
    "}\n",
    "historical_dict = {\n",
    "    \"period\": \"historical\",\n",
    "    \"train_period\": \"historical\",\n",
    "    \"initial_year\": years[0],\n",
    "    \"final_year\": years[2],\n",
    "    \"defor_value\": [1, 2],\n",
    "    \"time_interval\": years[2] - years[0],\n",
    "}\n",
    "forecast_dict = {\n",
    "    \"period\": \"forecast\",\n",
    "    \"train_period\": \"historical\",\n",
    "    \"initial_year\": years[0],\n",
    "    \"final_year\": years[2],\n",
    "    \"defor_value\": [1, 2],\n",
    "    \"time_interval\": years[2] - years[0],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e29cd3-018c-4bc0-b851-5a4acc7cab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el diccionario principal\n",
    "period_dict = {\n",
    "    calibration_dict[\"period\"]: calibration_dict,\n",
    "    validation_dict[\"period\"]: validation_dict,\n",
    "    historical_dict[\"period\"]: historical_dict,\n",
    "    forecast_dict[\"period\"]: forecast_dict,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af66ccc-8e4d-44be-8e21-884eab03a3b1",
   "metadata": {},
   "source": [
    "## Select input files based on period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739a47b-e2b1-489d-b34c-e0afa56a426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_independant_files(input_raster_files, period):\n",
    "    # Define the period-independent variables and their associated files\n",
    "    period_independant_variables = [\"altitude\", \"slope\", \"pa\", \"subj\"]\n",
    "    altitude_files = filter_files(input_raster_files, [\"altitude\"], None, False)\n",
    "    slope_files = filter_files(input_raster_files, [\"slope\"], None, False)\n",
    "    wdpa_files = filter_files(input_raster_files, [\"pa\"], None, False)\n",
    "    subj_files = filter_files(input_raster_files, [\"subj\"], None, False)\n",
    "\n",
    "    # Define the rivers and roads variables and their associated files\n",
    "    rivers_files = filter_files(\n",
    "        input_raster_files, [\"rivers\", \"reprojected\", \"distance\"], None, True\n",
    "    )\n",
    "    road_files = filter_files(\n",
    "        input_raster_files, [\"roads\", \"reprojected\", \"distance\"], None, True\n",
    "    )\n",
    "\n",
    "    # Define the period-dependent variables and their associated files\n",
    "    period_dictionary = period_dict[period]\n",
    "    initial_year = str(period_dictionary[\"initial_year\"])\n",
    "    final_year = str(period_dictionary[\"final_year\"])\n",
    "    exclude_year = \", \".join(\n",
    "        map(\n",
    "            str,\n",
    "            set(years)\n",
    "            - {period_dictionary[\"initial_year\"], period_dictionary[\"final_year\"]},\n",
    "        )\n",
    "    )\n",
    "    forest_loss_files = filter_files(\n",
    "        input_raster_files,\n",
    "        [forest_source, initial_year, final_year, \"forest\", \"loss\"],\n",
    "        [exclude_year, \"edge\"],\n",
    "        True,\n",
    "    )\n",
    "    forest_edge_files = filter_files(\n",
    "        input_raster_files,\n",
    "        [forest_source, initial_year, \"forest\", \"reprojected\", \"edge\"],\n",
    "        None,\n",
    "        True,\n",
    "    )\n",
    "    town_files = filter_files(\n",
    "        input_raster_files,\n",
    "        [initial_year, \"town\", \"reprojected\", \"distance\"],\n",
    "        None,\n",
    "        True,\n",
    "    )\n",
    "\n",
    "    # Create a dictionary with variable types as keys and file paths as values\n",
    "    variable_file_mapping = {\n",
    "        \"period\": period_dictionary[\"period\"],\n",
    "        \"altitude\": altitude_files[0],\n",
    "        \"slope\": slope_files[0],\n",
    "        \"pa\": wdpa_files[0],\n",
    "        \"subj\": subj_files[0],\n",
    "        \"dist_river\": rivers_files[0],\n",
    "        \"dist_road\": road_files[0],\n",
    "        \"dist_town\": town_files[0],\n",
    "        \"fcc\": forest_loss_files[0],\n",
    "        \"dist_edge\": forest_edge_files[0],\n",
    "    }\n",
    "    return variable_file_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b18f2a-6cd4-4650-a053-f210cb915ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_files = get_variable_independant_files(input_raster_files, \"calibration\")\n",
    "validation_files = get_variable_independant_files(input_raster_files, \"validation\")\n",
    "historical_files = get_variable_independant_files(input_raster_files, \"historical\")\n",
    "forecast_files = get_variable_independant_files(input_raster_files, \"forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3d7d6-839b-41fb-965b-363c286c1171",
   "metadata": {},
   "source": [
    "## Generate sample for the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5565b9-52e3-4ae2-9355-125ed66a8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sample points and extract raster values.\"\"\"\n",
    "\n",
    "# Import\n",
    "from glob import glob  # To explore files in a folder\n",
    "import os  # Operating system interfaces\n",
    "import sys  # To read and write files\n",
    "import uuid\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np  # For arrays\n",
    "from osgeo import gdal  # GIS libraries\n",
    "import pandas as pd  # To export result as a pandas DF\n",
    "\n",
    "# Local imports\n",
    "from forestatrisk.misc import makeblock, progress_bar\n",
    "\n",
    "\n",
    "def sample(\n",
    "    nsamp=10000,\n",
    "    adapt=True,\n",
    "    seed=1234,\n",
    "    csize=10,\n",
    "    var_dictionary=\"dictionary_of_files.txt\",\n",
    "    blk_rows=0,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"Sample points and extract raster values.\n",
    "\n",
    "    This function (i) randomly draws spatial points in deforested and\n",
    "    forested areas and (ii) extract environmental variable values for\n",
    "    each spatial point.\n",
    "\n",
    "    :param nsamp: Number of random spatial points.\n",
    "\n",
    "    :param adapt: Boolean. Adapt ``nsamp`` to forest area: 1000 for 1 Mha of\n",
    "        forest, with min=10000 and max=50000. Default to ``True``.\n",
    "\n",
    "    :param seed: Seed for random number generator.\n",
    "\n",
    "    :param csize: Spatial cell size in km.\n",
    "\n",
    "    :param var_dir: Directory with raster data.\n",
    "\n",
    "    :param blk_rows: If > 0, number of lines per block.\n",
    "\n",
    "    :param verbose: Toogle progress bar.\n",
    "\n",
    "    :return: A Pandas DataFrame, each row being one observation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    period_output_folder = sampling_folder / var_dictionary[\"period\"]\n",
    "    if not os.path.exists(period_output_folder):\n",
    "        os.makedirs(period_output_folder)\n",
    "\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # =============================================\n",
    "    # Sampling pixels\n",
    "    # =============================================\n",
    "\n",
    "    if verbose:\n",
    "        text = \"Sample 2x {} pixels (deforested vs. forest)\"\n",
    "        print(text.format(nsamp))\n",
    "\n",
    "    # Read defor raster\n",
    "    forest_raster_file = var_dictionary[\"fcc\"]\n",
    "    forestR = gdal.Open(forest_raster_file)\n",
    "    forestB = forestR.GetRasterBand(1)\n",
    "\n",
    "    # Make blocks\n",
    "    blockinfo = makeblock(forest_raster_file, blk_rows=blk_rows)\n",
    "    nblock = blockinfo[0]\n",
    "    nblock_x = blockinfo[1]\n",
    "    x = blockinfo[3]\n",
    "    y = blockinfo[4]\n",
    "    nx = blockinfo[5]\n",
    "    ny = blockinfo[6]\n",
    "    if verbose:\n",
    "        text = \"Divide region in {} blocks\"\n",
    "        print(text.format(nblock))\n",
    "\n",
    "    # Number of defor/forest pixels by block\n",
    "    if verbose:\n",
    "        text = \"Compute number of deforested and forest pixels per block\"\n",
    "        print(text)\n",
    "    ndc = 0\n",
    "    ndc_block = np.zeros(nblock, dtype=int)\n",
    "    nfc = 0\n",
    "    nfc_block = np.zeros(nblock, dtype=int)\n",
    "\n",
    "    # Loop on blocks of data\n",
    "    for b in range(nblock):\n",
    "        # Progress bar\n",
    "        if verbose:\n",
    "            progress_bar(nblock, b + 1)\n",
    "        # Position in 1D-arrays\n",
    "        px = b % nblock_x\n",
    "        py = b // nblock_x\n",
    "        # Read the data\n",
    "        forest = forestB.ReadAsArray(x[px], y[py], nx[px], ny[py])\n",
    "        # Identify pixels (x/y coordinates) which are deforested\n",
    "        deforpix = np.nonzero(forest == 0)\n",
    "        ndc_block[b] = len(deforpix[0])  # Number of defor pixels\n",
    "        ndc += len(deforpix[0])\n",
    "        # Identify pixels (x/y coordinates) which are forest\n",
    "        forpix = np.nonzero(forest == 1)\n",
    "        nfc_block[b] = len(forpix[0])  # Number of forest pixels\n",
    "        nfc += len(forpix[0])\n",
    "\n",
    "    # Adapt nsamp to forest area\n",
    "    if adapt is True:\n",
    "        gt = forestR.GetGeoTransform()\n",
    "        pix_area = gt[1] * (-gt[5])\n",
    "        farea = pix_area * (nfc + ndc) / 10000  # farea in ha\n",
    "        nsamp_prop = 1000 * farea / 1e6  # 1000 per 1Mha\n",
    "        if nsamp_prop >= 50000:\n",
    "            nsamp = 50000\n",
    "        elif nsamp_prop <= 10000:\n",
    "            nsamp = 10000\n",
    "        else:\n",
    "            nsamp = int(np.rint(nsamp_prop))\n",
    "\n",
    "    # Proba of drawing a block\n",
    "    if verbose:\n",
    "        print(\"Draw blocks at random\")\n",
    "    proba_block_d = ndc_block / ndc\n",
    "    proba_block_f = nfc_block / nfc\n",
    "    # Draw block number nsamp times\n",
    "    block_draw_d = np.random.choice(\n",
    "        list(range(nblock)), size=nsamp, replace=True, p=proba_block_d\n",
    "    )\n",
    "    block_draw_f = np.random.choice(\n",
    "        list(range(nblock)), size=nsamp, replace=True, p=proba_block_f\n",
    "    )\n",
    "    # Number of times the block is drawn\n",
    "    nblock_draw_d = np.zeros(nblock, dtype=int)\n",
    "    nblock_draw_f = np.zeros(nblock, dtype=int)\n",
    "    for s in range(nsamp):\n",
    "        nblock_draw_d[block_draw_d[s]] += 1\n",
    "        nblock_draw_f[block_draw_f[s]] += 1\n",
    "\n",
    "    # Draw defor/forest pixels in blocks\n",
    "    if verbose:\n",
    "        print(\"Draw pixels at random in blocks\")\n",
    "    # Object to store coordinates of selected pixels\n",
    "    deforselect = np.empty(shape=(0, 2), dtype=int)\n",
    "    forselect = np.empty(shape=(0, 2), dtype=int)\n",
    "    # Loop on blocks of data\n",
    "    for b in range(nblock):\n",
    "        # Progress bar\n",
    "        if verbose:\n",
    "            progress_bar(nblock, b + 1)\n",
    "        # nbdraw\n",
    "        nbdraw_d = nblock_draw_d[b]\n",
    "        nbdraw_f = nblock_draw_f[b]\n",
    "        # Position in 1D-arrays\n",
    "        px = b % nblock_x\n",
    "        py = b // nblock_x\n",
    "        # Read the data\n",
    "        forest = forestB.ReadAsArray(x[px], y[py], nx[px], ny[py])\n",
    "        # Identify pixels (x/y coordinates) which are deforested\n",
    "        # !! Values returned in row-major, C-style order (y/x) !!\n",
    "        deforpix = np.nonzero(forest == 0)\n",
    "        deforpix = np.transpose((x[px] + deforpix[1], y[py] + deforpix[0]))\n",
    "        ndc_block = len(deforpix)\n",
    "        # Identify pixels (x/y coordinates) which are forested\n",
    "        forpix = np.nonzero(forest == 1)\n",
    "        forpix = np.transpose((x[px] + forpix[1], y[py] + forpix[0]))\n",
    "        nfc_block = len(forpix)\n",
    "        # Sample deforested pixels\n",
    "        if nbdraw_d > 0:\n",
    "            if nbdraw_d < ndc_block:\n",
    "                i = np.random.choice(ndc_block, size=nbdraw_d, replace=False)\n",
    "                deforselect = np.concatenate((deforselect, deforpix[i]), axis=0)\n",
    "            else:\n",
    "                # nbdraw = ndc_block\n",
    "                deforselect = np.concatenate((deforselect, deforpix), axis=0)\n",
    "        # Sample forest pixels\n",
    "        if nbdraw_f > 0:\n",
    "            if nbdraw_f < nfc_block:\n",
    "                i = np.random.choice(nfc_block, size=nbdraw_f, replace=False)\n",
    "                forselect = np.concatenate((forselect, forpix[i]), axis=0)\n",
    "            else:\n",
    "                # nbdraw = ndc_block\n",
    "                forselect = np.concatenate((forselect, forpix), axis=0)\n",
    "\n",
    "    # =============================================\n",
    "    # Compute center of pixel coordinates\n",
    "    # =============================================\n",
    "    if verbose:\n",
    "        print(\"Compute center of pixel coordinates\")\n",
    "\n",
    "    # Landscape variables from forest raster\n",
    "    gt = forestR.GetGeoTransform()\n",
    "    ncol_r = forestR.RasterXSize\n",
    "    nrow_r = forestR.RasterYSize\n",
    "    Xmin = gt[0]\n",
    "    Xmax = gt[0] + gt[1] * ncol_r\n",
    "    Ymin = gt[3] + gt[5] * nrow_r\n",
    "    Ymax = gt[3]\n",
    "\n",
    "    # Dereference driver\n",
    "    forestB = None\n",
    "    del forestR\n",
    "\n",
    "    # Concatenate selected pixels\n",
    "    select = np.concatenate((deforselect, forselect), axis=0)\n",
    "\n",
    "    # Offsets and coordinates #\n",
    "    xOffset = select[:, 0]\n",
    "    yOffset = select[:, 1]\n",
    "    pts_x = (xOffset + 0.5) * gt[1] + gt[0]  # +0.5 for center of pixels\n",
    "    pts_y = (yOffset + 0.5) * gt[5] + gt[3]  # +0.5 for center of pixels\n",
    "\n",
    "    # ================================================\n",
    "    # Compute cell number for spatial autocorrelation\n",
    "    # ================================================\n",
    "\n",
    "    # Cell number from region\n",
    "    if verbose:\n",
    "        text = \"Compute number of {} x {} km spatial cells\"\n",
    "        print(text.format(csize, csize))\n",
    "    csize = csize * 1000  # Transform km in m\n",
    "    ncol = int(np.ceil((Xmax - Xmin) / csize))\n",
    "    nrow = int(np.ceil((Ymax - Ymin) / csize))\n",
    "    ncell = ncol * nrow\n",
    "    if verbose:\n",
    "        text = \"... {} cells ({} x {})\"\n",
    "        print(text.format(ncell, nrow, ncol))\n",
    "    # bigI and bigJ are the coordinates of the cells and start at zero\n",
    "    if verbose:\n",
    "        print(\"Identify cell number from XY coordinates\")\n",
    "    bigJ = ((pts_x - Xmin) / csize).astype(int)\n",
    "    bigI = ((Ymax - pts_y) / csize).astype(int)\n",
    "    cell = bigI * ncol + bigJ  # Cell number starts at zero\n",
    "\n",
    "    # =============================================\n",
    "    # Extract values from rasters\n",
    "    # =============================================\n",
    "\n",
    "    # Raster list\n",
    "    # Extract keys excluding 'fcc' and sort them\n",
    "    sorted_keys = sorted([key for key in var_dictionary.keys() if key != \"period\"])\n",
    "\n",
    "    # Retrieve the corresponding file paths based on the sorted keys\n",
    "    raster_list = [var_dictionary[key] for key in sorted_keys]\n",
    "\n",
    "    # Make vrt with gdal.BuildVRT\n",
    "    # Note: Extent and resolution from forest raster!\n",
    "    if verbose:\n",
    "        text = \"Make virtual raster with variables as raster bands\"\n",
    "        print(text)\n",
    "    param = gdal.BuildVRTOptions(\n",
    "        resolution=\"user\",\n",
    "        outputBounds=(Xmin, Ymin, Xmax, Ymax),\n",
    "        xRes=gt[1],\n",
    "        yRes=-gt[5],\n",
    "        separate=True,\n",
    "    )\n",
    "    rand_uuid = uuid.uuid4()\n",
    "    vrt_file = f\"/vsimem/var_{rand_uuid}.vrt\"\n",
    "    gdal.BuildVRT(vrt_file, raster_list, options=param)\n",
    "    stack = gdal.Open(vrt_file)\n",
    "\n",
    "    # List of nodata values\n",
    "    nband = stack.RasterCount\n",
    "    bandND = np.zeros(nband)\n",
    "    for k in range(nband):\n",
    "        band = stack.GetRasterBand(k + 1)\n",
    "        bandND[k] = band.GetNoDataValue()\n",
    "        if bandND[k] is None:\n",
    "            print(\n",
    "                \"NoData value is not specified \\\n",
    "            for input raster file \"\n",
    "                + raster_list[k]\n",
    "            )\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Numpy array to store values\n",
    "    nobs = select.shape[0]\n",
    "    val = np.zeros(shape=(nobs, nband), dtype=float)\n",
    "\n",
    "    # Extract raster values\n",
    "    if verbose:\n",
    "        text = \"Extract raster values for selected pixels\"\n",
    "        print(text)\n",
    "    for i in range(nobs):\n",
    "        # Progress bar\n",
    "        if verbose:\n",
    "            progress_bar(nobs, i + 1)\n",
    "        # ReadArray for extract\n",
    "        extract = stack.ReadAsArray(int(xOffset[i]), int(yOffset[i]), 1, 1)\n",
    "        val[i, :] = extract.reshape(\n",
    "            nband,\n",
    "        )\n",
    "\n",
    "    # Close stack\n",
    "    del stack\n",
    "\n",
    "    # Replace NA\n",
    "    # NB: ReadAsArray return float32 type\n",
    "    bandND = bandND.astype(np.float32)\n",
    "    for k in range(nband):\n",
    "        val[val[:, k] == bandND[k], k] = np.nan\n",
    "\n",
    "    # Add XY coordinates and cell number\n",
    "    pts_x.shape = (nobs, 1)\n",
    "    pts_y.shape = (nobs, 1)\n",
    "    cell.shape = (nobs, 1)\n",
    "    val = np.concatenate((val, pts_x, pts_y, cell), axis=1)\n",
    "\n",
    "    # =============================================\n",
    "    # Export and return value\n",
    "    # =============================================\n",
    "\n",
    "    # Save csize for interpolation of rhos\n",
    "    ofile = os.path.join(period_output_folder, \"csize_icar.txt\")\n",
    "    with open(ofile, \"w\", encoding=\"utf-8\") as f:\n",
    "        csize_km = csize / 1000\n",
    "        f.write(str(csize_km))\n",
    "    output_file = str(period_output_folder / \"sample.txt\")\n",
    "    if verbose:\n",
    "        text = \"Export results to file {}\"\n",
    "        print(text.format(output_file))\n",
    "\n",
    "    # Write to file by row\n",
    "    colname = sorted_keys\n",
    "    # for (i, j) in enumerate(sorted_keys):\n",
    "    #     base_name = os.path.basename(j)\n",
    "    #     index_dot = base_name.index(\".\")\n",
    "    #     colname[i] = base_name[:index_dot]\n",
    "\n",
    "    varname = \",\".join(colname) + \",X,Y,cell\"\n",
    "    np.savetxt(output_file, val, header=varname, fmt=\"%s\", delimiter=\",\", comments=\"\")\n",
    "\n",
    "    # Convert to pandas DataFrame and return the result\n",
    "    colname.extend([\"X\", \"Y\", \"cell\"])\n",
    "    val_df = pd.DataFrame(val, columns=colname)\n",
    "\n",
    "    # Remove NA from data-set (otherwise scale() and\n",
    "    # model_binomial_iCAR don't work)\n",
    "    dataset = val_df.dropna(axis=0).copy()\n",
    "    print(f\"Number of samples: {len(dataset)}\")\n",
    "    # Set number of trials to one for far.model_binomial_iCAR()\n",
    "    dataset.loc[:, \"trial\"] = 1  # Sample size\n",
    "    ndefor = sum(dataset.fcc == 0)\n",
    "    nfor = sum(dataset.fcc == 1)\n",
    "    ifile = str(period_output_folder / \"sample_size.csv\")\n",
    "    with open(ifile, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Var, n\\n\")\n",
    "        file.write(f\"ndefor, {ndefor}\\n\")\n",
    "        file.write(f\"nfor, {nfor}\\n\")\n",
    "    print(f\"Sample size: ndefor = {ndefor}, nfor = {nfor}\")\n",
    "\n",
    "\n",
    "# End\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718ed55-e518-4c7e-a7c9-ba109528a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_samples = sample(\n",
    "    n_samples, adapt, random_seed, spatial_cell_size_km, calibration_files\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceea8a3-0f27-4957-8d32-e61ee31879ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_samples = sample(\n",
    "    n_samples, adapt, random_seed, spatial_cell_size_km, historical_files\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb52139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deforisk-jupyter-nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
