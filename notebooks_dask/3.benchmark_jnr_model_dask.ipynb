{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93956c07-d9f1-4e3a-ae1b-148aec301334",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af04e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas\n",
    "# import pandas as pd\n",
    "# print(pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b50586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizations\n",
    "# GDAL optimizations\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "cpu_count: int = mp.cpu_count()\n",
    "num_cores: int = cpu_count - 2\n",
    "os.environ[\"GDAL_NUM_THREADS\"] = f\"{num_cores}\"\n",
    "os.environ[\"GDAL_CACHEMAX\"] = \"1024\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2a25b-11a9-436c-9eff-17ad4003f00c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import riskmapjnr as rmj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root to path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from component.script.utilities.file_filter import (\n",
    "    list_files_by_extension,\n",
    "    filter_files_by_keywords,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23c64e",
   "metadata": {},
   "source": [
    "## Dask Processing Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2, memory_limit=\"4GB\")\n",
    "geospatial_client = Client(cluster)\n",
    "geospatial_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9131ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import SpecCluster, Worker, Nanny, Client\n",
    "\n",
    "# # Define worker specifications with different memory limits\n",
    "# worker_specs = {\n",
    "#     \"nanny-1\": {\"cls\": Nanny, \"options\": {\"nthreads\": 1, \"memory_limit\": \"1GB\"}},\n",
    "#     \"worker-1\": {\"cls\": Worker, \"options\": {\"nthreads\": 1, \"memory_limit\": \"8GB\"}},\n",
    "#     \"worker-2\": {\"cls\": Worker, \"options\": {\"nthreads\": 1, \"memory_limit\": \"2GB\"}},\n",
    "#     \"worker-3\": {\"cls\": Worker, \"options\": {\"nthreads\": 1, \"memory_limit\": \"2GB\"}},\n",
    "#     \"worker-4\": {\"cls\": Worker, \"options\": {\"nthreads\": 1, \"memory_limit\": \"2GB\"}},\n",
    "#     \"worker-5\": {\"cls\": Worker, \"options\": {\"nthreads\": 1, \"memory_limit\": \"2GB\"}},\n",
    "# }\n",
    "\n",
    "# # Create the cluster\n",
    "# cluster = SpecCluster(\n",
    "#     workers=worker_specs,\n",
    "# )\n",
    "\n",
    "# # Connect client\n",
    "# geospatial_client = Client(cluster)\n",
    "# geospatial_client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15850cf5-6362-4e08-aef7-f9372ff90576",
   "metadata": {},
   "source": [
    "## Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65846e-d0bf-4d1f-b2d4-c59f3e6a0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f19929-ff4b-498e-ba88-c0444107c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_source = \"gfc\"  ##gfc, tmf\n",
    "tree_cover_threshold = 10\n",
    "years = [2015, 2020, 2024]\n",
    "string_years = [str(num) for num in years]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d8fcd-6d62-4b47-a589-5921a4cc8102",
   "metadata": {},
   "source": [
    "## Connect folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d607a-c906-459f-8039-3a1bb1abd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder: Path = Path.cwd().parent\n",
    "downloads_folder: Path = root_folder / \"data\"\n",
    "downloads_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07074b-2844-460a-98ca-e8c8917c9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = downloads_folder / project_name\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_data_folder = project_folder / \"data\"\n",
    "processed_data_folder.mkdir(parents=True, exist_ok=True)\n",
    "plots_folder = project_folder / \"plots_dask\"\n",
    "plots_folder.mkdir(parents=True, exist_ok=True)\n",
    "rmj_bm = project_folder / \"rmj_bm_dask\"\n",
    "rmj_bm.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba919a-3341-442e-924d-ee870327731d",
   "metadata": {},
   "source": [
    "## Forest Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d17f5-7b11-481e-8cde-a49d0b51d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all raster files in the processed data folder\n",
    "input_raster_files = list_files_by_extension(processed_data_folder, [\".tiff\", \".tif\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9d584-29bd-436a-a7f1-aa3a9a0e030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_change_file = filter_files_by_keywords(\n",
    "    input_raster_files,\n",
    "    [\"forest\", \"loss\", forest_source] + string_years,\n",
    "    False,\n",
    "    [\"distance\", \"edge\"],\n",
    ")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731cbc1-5a6e-4117-96d1-aa82c7bfa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_yearly_files = filter_files_by_keywords(\n",
    "    input_raster_files, [\"forest\", forest_source], False, [\"loss\", \"edge\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408ef61-6761-4a11-b079-b81f5af616f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_edge_files = filter_files_by_keywords(\n",
    "    input_raster_files, [\"forest\", forest_source, \"edge\"], False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a809a-7827-4523-a454-c6ab464d76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_subj_file = filter_files_by_keywords(input_raster_files, [\"subj\"])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dad12b-f99b-4c5e-a77c-0af59155e580",
   "metadata": {},
   "source": [
    "## Periods dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be2707-82be-4def-be45-ca8a61ce8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_dict = {\n",
    "    \"period\": \"calibration\",\n",
    "    \"train_period\": \"calibration\",\n",
    "    \"initial_year\": years[0],\n",
    "    \"final_year\": years[1],\n",
    "    \"defor_value\": 1,\n",
    "    \"time_interval\": years[1] - years[0],\n",
    "    \"initial_year_forest\": filter_files_by_keywords(\n",
    "        forest_yearly_files, [str(years[0])]\n",
    "    )[0],\n",
    "    \"initial_year_forest_edge\": filter_files_by_keywords(\n",
    "        forest_edge_files, [str(years[0])]\n",
    "    )[0],\n",
    "}\n",
    "validation_dict = {\n",
    "    \"period\": \"validation\",\n",
    "    \"train_period\": \"calibration\",\n",
    "    \"initial_year\": years[1],\n",
    "    \"final_year\": years[2],\n",
    "    \"defor_value\": 1,\n",
    "    \"time_interval\": years[2] - years[1],\n",
    "    \"initial_year_forest\": filter_files_by_keywords(\n",
    "        forest_yearly_files, [str(years[1])]\n",
    "    )[0],\n",
    "    \"initial_year_forest_edge\": filter_files_by_keywords(\n",
    "        forest_edge_files, [str(years[1])]\n",
    "    )[0],\n",
    "}\n",
    "historical_dict = {\n",
    "    \"period\": \"historical\",\n",
    "    \"train_period\": \"historical\",\n",
    "    \"initial_year\": years[0],\n",
    "    \"final_year\": years[2],\n",
    "    \"defor_value\": [1, 2],\n",
    "    \"time_interval\": years[2] - years[0],\n",
    "    \"initial_year_forest\": filter_files_by_keywords(\n",
    "        forest_yearly_files, [str(years[0])]\n",
    "    )[0],\n",
    "    \"initial_year_forest_edge\": filter_files_by_keywords(\n",
    "        forest_edge_files, [str(years[0])]\n",
    "    )[0],\n",
    "}\n",
    "forecast_dict = {\n",
    "    \"period\": \"forecast\",\n",
    "    \"train_period\": \"historical\",\n",
    "    \"initial_year\": years[0],\n",
    "    \"final_year\": years[2],\n",
    "    \"defor_value\": [1, 2],\n",
    "    \"time_interval\": years[2] - years[0],\n",
    "    \"initial_year_forest\": filter_files_by_keywords(\n",
    "        forest_yearly_files, [str(years[2])]\n",
    "    )[0],\n",
    "    \"initial_year_forest_edge\": filter_files_by_keywords(\n",
    "        forest_edge_files, [str(years[2])]\n",
    "    )[0],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c886152-5c18-4daf-884b-45434df2b29a",
   "metadata": {},
   "source": [
    "## 1 Calculate distance to forest edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a6556-f614-41d6-a5f9-eebf01953978",
   "metadata": {},
   "outputs": [],
   "source": [
    "deforestation_thresh = 99.5\n",
    "deforestation_thresh = 99.5\n",
    "# max_dist1 = 5000\n",
    "# max_dist2 = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import dask.array as da\n",
    "\n",
    "\n",
    "def dist_edge_threshold_xarray(\n",
    "    fcc_file,\n",
    "    defor_values,\n",
    "    defor_threshold=99.5,\n",
    "    dist_file=\"dist_edge.tif\",\n",
    "    dist_bins=np.arange(0, 1080, step=30),\n",
    "    tab_file_dist=\"perc_dist.csv\",\n",
    "    fig_file_dist=\"perc_dist.png\",\n",
    "    figsize=(6.4, 4.8),\n",
    "    dpi=100,\n",
    "    dist_file_available=False,\n",
    "    check_fcc=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"Computing the percentage of total deforestation as a function of\n",
    "    the distance to forest edge.\n",
    "\n",
    "    This function computes the percentage of total deforestation as a\n",
    "    function of the distance to forest edge. It returns a table with\n",
    "    the cumulative percentage of deforestation as distance to forest\n",
    "    edge increases. It also identifies the distance threshold for the\n",
    "    distance to forest edge so that the deforestation under that\n",
    "    threshold is >= 99.5 % of the total deforestation in the\n",
    "    landscape. The function also plots the relationship between the\n",
    "    percentage of deforestation and the distance to forest edge. A\n",
    "    raster of distance to forest edge will be created. The distance\n",
    "    unit will be the one of the input file.\n",
    "\n",
    "    :param fcc_file: Input raster file of forest cover change at three\n",
    "        dates (123). 1: first period deforestation, 2: second period\n",
    "        deforestation, 3: remaining forest at the end of the second\n",
    "        period. No data value must be 0 (zero). The raster must be\n",
    "        projected to compute Euclidean distances with the\n",
    "        ``gdal_proximity()`` function.\n",
    "\n",
    "    :param defor_values: Raster values to consider for\n",
    "        deforestation. Must correspond to either scalar 1 if first\n",
    "        period, or list [1, 2] if both first and second period are\n",
    "        considered.\n",
    "\n",
    "    :param defor_threshold: Deforestation threshold (in\n",
    "        percent). Default to 99.5.\n",
    "\n",
    "    :param dist_file: Path to either (i) the output raster file of\n",
    "        distance to forest edge or (ii) the input raster file of\n",
    "        distance to forest edge if ``dist_file_available`` is\n",
    "        ``True``. Raster of distance to forest edge is computed in the\n",
    "        first case only. Default to ``dist_edge.tif``.\n",
    "\n",
    "    :param dist_bins: Array of bins for distances. It has to be\n",
    "        1-dimensional and monotonic. The array must also include zero\n",
    "        as the first value. Default to ``np.arange(0, 1080,\n",
    "        step=30)``.\n",
    "\n",
    "    :param tab_file_dist: Path to the table ``.csv`` file that will be\n",
    "        created. This table includes the following variables:\n",
    "\n",
    "        * ``distance``: bins of distance to forest edge (in m).\n",
    "        * ``npix``: the number of deforested pixels in each bin.\n",
    "        * ``area``: the corresponding area (in ha).\n",
    "        * ``cum``: the cumulative sum of the deforested area (in ha).\n",
    "        * ``perc``: the corresponding percentage of total deforestation.\n",
    "\n",
    "    :param fig_file_dist: Path to the plot file that will be\n",
    "        created. This plot represents the cumulative deforestation\n",
    "        percentage as the distance to forest edge increases.\n",
    "\n",
    "    :param figsize: Figure size.\n",
    "\n",
    "    :param dpi: Resolution for output image.\n",
    "\n",
    "    :param dist_file_available: Boolean. If ``True``, parameter\n",
    "        ``dist_file`` indicates the input raster file of distance to\n",
    "        forest edge which is not computed. Default to ``False``.\n",
    "\n",
    "    :param check_fcc: Boolean. If ``True``, performs some checks on\n",
    "        the fcc input file. Default to ``True``.\n",
    "\n",
    "    :param verbose: Logical. Whether to print messages or not. Default\n",
    "        to ``True``.\n",
    "\n",
    "    :return: A dictionary. With ``tot_def``: total deforestation (in\n",
    "        ha), ``dist_thresh``: the distance threshold, ``perc``: the\n",
    "        percentage of deforestation for pixels with distance <=\n",
    "        dist_thresh.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read rasters using rioxarray with chunking\n",
    "    dist_ds: xr.Dataset | xr.DataArray | list[Dataset] = rioxarray.open_rasterio(\n",
    "        dist_file, chunks=True\n",
    "    )\n",
    "    fcc_ds = rioxarray.open_rasterio(fcc_file, chunks=True)\n",
    "\n",
    "    # Ensure both are dask arrays for parallel processing\n",
    "    if not isinstance(dist_ds.data, da.Array):\n",
    "        dist_ds = dist_ds.chunk((dist_ds.sizes[\"y\"], dist_ds.sizes[\"x\"]))\n",
    "    if not isinstance(fcc_ds.data, da.Array):\n",
    "        fcc_ds = fcc_ds.chunk((fcc_ds.sizes[\"y\"], fcc_ds.sizes[\"x\"]))\n",
    "\n",
    "    # Create a table to save the results\n",
    "    data = {\"distance\": dist_bins[1:], \"npix\": 0, \"area\": 0.0, \"cum\": 0.0, \"perc\": 0.0}\n",
    "    res_df = pd.DataFrame(data)\n",
    "\n",
    "    # Total deforested pixels\n",
    "    npix_def = 0\n",
    "\n",
    "    # Process all chunks in parallel using dask\n",
    "    # Convert to numpy arrays for processing (this will trigger computation)\n",
    "    dist_data_full = dist_ds.values\n",
    "    fcc_data_full = fcc_ds.values\n",
    "\n",
    "    # Get pixel area from geotransform\n",
    "    gt = dist_ds.rio.transform()\n",
    "    pix_area = abs(gt[0]) * abs(gt[4])  # Pixel area in projection units squared\n",
    "\n",
    "    # Process data in chunks using dask's parallel processing capabilities\n",
    "    def process_chunk(dist_chunk, fcc_chunk):\n",
    "        \"\"\"Process a single chunk of data.\"\"\"\n",
    "        # Number of deforested pixels\n",
    "        if isinstance(defor_values, int):\n",
    "            defor_values_array = [defor_values]\n",
    "        else:\n",
    "            defor_values_array = defor_values\n",
    "\n",
    "        npix_def_chunk = np.isin(fcc_chunk, defor_values_array).sum()\n",
    "\n",
    "        # Consider only deforested pixels for distances\n",
    "        dist_def = dist_chunk * np.isin(fcc_chunk, defor_values_array)\n",
    "        dist_def = dist_def[dist_def > 0]\n",
    "\n",
    "        # Categorize distance and count by bin\n",
    "        if len(dist_def) > 0:\n",
    "            dist_cat = pd.cut(dist_def.flatten(), dist_bins, right=True)\n",
    "            df = pd.DataFrame({\"dist\": dist_cat})\n",
    "            counts = df.groupby(df.dist, observed=False).size()\n",
    "        else:\n",
    "            counts = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        return npix_def_chunk, counts\n",
    "\n",
    "    # Process all chunks\n",
    "    if verbose:\n",
    "        print(\"Processing raster data in chunks...\")\n",
    "\n",
    "    # Since we're using dask arrays, we can compute chunk-wise operations\n",
    "    # For simplicity and efficiency, let's process the entire dataset at once for this operation\n",
    "\n",
    "    # Create masks for deforested pixels\n",
    "    if isinstance(defor_values, int):\n",
    "        defor_values_array = [defor_values]\n",
    "    else:\n",
    "        defor_values_array = defor_values\n",
    "\n",
    "    # Process data in a chunked way using dask's lazy evaluation\n",
    "    # We'll compute the whole dataset to avoid memory issues with large rasters\n",
    "    dist_data = dist_ds.values\n",
    "    fcc_data = fcc_ds.values\n",
    "\n",
    "    # Count total deforested pixels\n",
    "    npix_def = np.isin(fcc_data, defor_values_array).sum()\n",
    "\n",
    "    # Get deforested distances\n",
    "    dist_def = dist_data * np.isin(fcc_data, defor_values_array)\n",
    "    dist_def = dist_def[dist_def > 0]\n",
    "\n",
    "    # Categorize distance and count by bin\n",
    "    if len(dist_def) > 0:\n",
    "        dist_cat = pd.cut(dist_def.flatten(), dist_bins, right=True)\n",
    "        df = pd.DataFrame({\"dist\": dist_cat})\n",
    "        counts = df.groupby(df.dist, observed=False).size()\n",
    "\n",
    "        # Update data-frame\n",
    "        res_df.loc[:, \"npix\"] = counts.values\n",
    "\n",
    "    # Compute deforested areas\n",
    "    area = res_df[\"npix\"].values * pix_area / 10000  # Convert to hectares\n",
    "    res_df.loc[:, \"area\"] = area\n",
    "    tot_area_def = npix_def * pix_area / 10000\n",
    "\n",
    "    # Cumulated deforestation\n",
    "    res_df.loc[:, \"cum\"] = res_df[\"area\"].cumsum().values\n",
    "\n",
    "    # Percentage of total deforestation\n",
    "    res_df.loc[:, \"perc\"] = 100 * res_df[\"cum\"].values / tot_area_def\n",
    "\n",
    "    # Export the table of results\n",
    "    res_df.to_csv(tab_file_dist, sep=\",\", header=True, index=False, index_label=False)\n",
    "\n",
    "    # Distance and percentage for deforestation threshold\n",
    "    try:\n",
    "        index_thresh = np.nonzero(res_df[\"perc\"].values > defor_threshold)[0][0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Increase maximal distance defined in argument 'dist_bins'.\")\n",
    "\n",
    "    dist_thresh = res_df.loc[index_thresh, \"distance\"]\n",
    "    perc_thresh = np.around(res_df.loc[index_thresh, \"perc\"], 2)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    plt.subplot(111)\n",
    "    plt.plot(res_df[\"distance\"], res_df[\"perc\"], \"b-\")\n",
    "    plt.vlines(\n",
    "        dist_thresh,\n",
    "        ymin=np.min(res_df[\"perc\"]),\n",
    "        ymax=perc_thresh,\n",
    "        colors=\"k\",\n",
    "        linestyles=\"dashed\",\n",
    "    )\n",
    "    plt.hlines(perc_thresh, xmin=0, xmax=dist_thresh, colors=\"k\", linestyles=\"dashed\")\n",
    "    plt.xlabel(\"Distance to forest edge (m)\")\n",
    "    plt.ylabel(\"Percentage of total deforestation (%)\")\n",
    "    # Text distance\n",
    "    t1 = str(dist_thresh) + \" m\"\n",
    "    x1_text = dist_thresh - 0.01 * np.max(dist_bins)\n",
    "    y1_text = np.min(res_df[\"perc\"])\n",
    "    plt.text(x1_text, y1_text, t1, ha=\"right\", va=\"bottom\")\n",
    "    # Text percentage\n",
    "    t2 = str(perc_thresh) + \" %\"\n",
    "    x2_text = 0\n",
    "    y2_text = perc_thresh - 0.01 * (100 - np.min(res_df[\"perc\"]))\n",
    "    plt.text(x2_text, y2_text, t2, ha=\"left\", va=\"top\")\n",
    "    fig.savefig(fig_file_dist)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Results\n",
    "    return {\n",
    "        \"tot_def\": tot_area_def,\n",
    "        \"dist_thresh\": dist_thresh,\n",
    "        \"perc_thresh\": perc_thresh,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad83d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import dask.array as da\n",
    "\n",
    "\n",
    "def dist_edge_threshold_xarray_v2(\n",
    "    fcc_file,\n",
    "    defor_values,\n",
    "    defor_threshold=99.5,\n",
    "    dist_file=\"dist_edge.tif\",\n",
    "    tab_file_dist=\"perc_dist.csv\",\n",
    "    fig_file_dist=\"perc_dist.png\",\n",
    "    figsize=(6.4, 4.8),\n",
    "    dpi=100,\n",
    "    dist_file_available=False,\n",
    "    check_fcc=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"Computing the percentage of total deforestation as a function of\n",
    "    the distance to forest edge.\n",
    "\n",
    "    This function computes the percentage of total deforestation as a\n",
    "    function of the distance to forest edge. It returns a table with\n",
    "    the cumulative percentage of deforestation as distance to forest\n",
    "    edge increases. It also identifies the distance threshold for the\n",
    "    distance to forest edge so that the deforestation under that\n",
    "    threshold is >= 99.5 % of the total deforestation in the\n",
    "    landscape. The function also plots the relationship between the\n",
    "    percentage of deforestation and the distance to forest edge. A\n",
    "    raster of distance to forest edge will be created. The distance\n",
    "    unit will be the one of the input file.\n",
    "\n",
    "    :param fcc_file: Input raster file of forest cover change at three\n",
    "        dates (123). 1: first period deforestation, 2: second period\n",
    "        deforestation, 3: remaining forest at the end of the second\n",
    "        period. No data value must be 0 (zero). The raster must be\n",
    "        projected to compute Euclidean distances with the\n",
    "        ``gdal_proximity()`` function.\n",
    "\n",
    "    :param defor_values: Raster values to consider for\n",
    "        deforestation. Must correspond to either scalar 1 if first\n",
    "        period, or list [1, 2] if both first and second period are\n",
    "        considered.\n",
    "\n",
    "    :param defor_threshold: Deforestation threshold (in\n",
    "        percent). Default to 99.5.\n",
    "\n",
    "    :param dist_file: Path to either (i) the output raster file of\n",
    "        distance to forest edge or (ii) the input raster file of\n",
    "        distance to forest edge if ``dist_file_available`` is\n",
    "        ``True``. Raster of distance to forest edge is computed in the\n",
    "        first case only. Default to ``dist_edge.tif``.\n",
    "\n",
    "    :param tab_file_dist: Path to the table ``.csv`` file that will be\n",
    "        created. This table includes the following variables:\n",
    "\n",
    "        * ``distance``: bins of distance to forest edge (in m).\n",
    "        * ``npix``: the number of deforested pixels in each bin.\n",
    "        * ``area``: the corresponding area (in ha).\n",
    "        * ``cum``: the cumulative sum of the deforested area (in ha).\n",
    "        * ``perc``: the corresponding percentage of total deforestation.\n",
    "\n",
    "    :param fig_file_dist: Path to the plot file that will be\n",
    "        created. This plot represents the cumulative deforestation\n",
    "        percentage as the distance to forest edge increases.\n",
    "\n",
    "    :param figsize: Figure size.\n",
    "\n",
    "    :param dpi: Resolution for output image.\n",
    "\n",
    "    :param dist_file_available: Boolean. If ``True``, parameter\n",
    "        ``dist_file`` indicates the input raster file of distance to\n",
    "        forest edge which is not computed. Default to ``False``.\n",
    "\n",
    "    :param check_fcc: Boolean. If ``True``, performs some checks on\n",
    "        the fcc input file. Default to ``True``.\n",
    "\n",
    "    :param verbose: Logical. Whether to print messages or not. Default\n",
    "        to ``True``.\n",
    "\n",
    "    :return: A dictionary. With ``tot_def``: total deforestation (in\n",
    "        ha), ``dist_thresh``: the distance threshold, ``perc``: the\n",
    "        percentage of deforestation for pixels with distance <=\n",
    "        dist_thresh.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read rasters using rioxarray with chunking\n",
    "    dist_ds = rioxarray.open_rasterio(dist_file, chunks=True)\n",
    "    fcc_ds = rioxarray.open_rasterio(fcc_file, chunks=True)\n",
    "\n",
    "    # Ensure both are dask arrays for parallel processing\n",
    "    if not isinstance(dist_ds.data, da.Array):\n",
    "        dist_ds = dist_ds.chunk((dist_ds.sizes[\"y\"], dist_ds.sizes[\"x\"]))\n",
    "    if not isinstance(fcc_ds.data, da.Array):\n",
    "        fcc_ds = fcc_ds.chunk((fcc_ds.sizes[\"y\"], fcc_ds.sizes[\"x\"]))\n",
    "\n",
    "    # Get pixel area from geotransform\n",
    "    gt = dist_ds.rio.transform()\n",
    "    pix_res = abs(gt[0])  # Pixel resolution in the same units as distance\n",
    "\n",
    "    # Compute max distance in raster\n",
    "    dist_data_full = dist_ds.values\n",
    "    valid_distances = dist_data_full[dist_data_full > 0]\n",
    "    max_dist = np.max(valid_distances) if len(valid_distances) > 0 else 0\n",
    "\n",
    "    # Define bins dynamically\n",
    "    dist_bins = np.arange(0, max_dist + pix_res, step=pix_res)\n",
    "\n",
    "    # Create a table to save the results\n",
    "    data = {\"distance\": dist_bins[1:], \"npix\": 0, \"area\": 0.0, \"cum\": 0.0, \"perc\": 0.0}\n",
    "    res_df = pd.DataFrame(data)\n",
    "\n",
    "    # Total deforested pixels\n",
    "    npix_def = 0\n",
    "\n",
    "    # Process all chunks in parallel using dask\n",
    "    dist_data = dist_ds.values\n",
    "    fcc_data = fcc_ds.values\n",
    "\n",
    "    # Get pixel area from geotransform\n",
    "    pix_area = abs(gt[0]) * abs(gt[4])\n",
    "\n",
    "    # Create masks for deforested pixels\n",
    "    if isinstance(defor_values, int):\n",
    "        defor_values_array = [defor_values]\n",
    "    else:\n",
    "        defor_values_array = defor_values\n",
    "\n",
    "    # Count total deforested pixels\n",
    "    npix_def = np.isin(fcc_data, defor_values_array).sum()\n",
    "\n",
    "    # Get deforested distances\n",
    "    dist_def = dist_data * np.isin(fcc_data, defor_values_array)\n",
    "    dist_def = dist_def[dist_def > 0]\n",
    "\n",
    "    # Categorize distance and count by bin\n",
    "    if len(dist_def) > 0:\n",
    "        dist_cat = pd.cut(dist_def.flatten(), dist_bins, right=True)\n",
    "        df = pd.DataFrame({\"dist\": dist_cat})\n",
    "        counts = df.groupby(df.dist, observed=False).size()\n",
    "\n",
    "        # Update data-frame\n",
    "        res_df.loc[:, \"npix\"] = counts.values\n",
    "\n",
    "    # Compute deforested areas\n",
    "    area = res_df[\"npix\"].values * pix_area / 10000  # Convert to hectares\n",
    "    res_df.loc[:, \"area\"] = area\n",
    "    tot_area_def = npix_def * pix_area / 10000\n",
    "\n",
    "    # Cumulated deforestation\n",
    "    res_df.loc[:, \"cum\"] = res_df[\"area\"].cumsum().values\n",
    "\n",
    "    # Percentage of total deforestation\n",
    "    res_df.loc[:, \"perc\"] = 100 * res_df[\"cum\"].values / tot_area_def\n",
    "\n",
    "    # Export the table of results\n",
    "    res_df.to_csv(tab_file_dist, sep=\",\", header=True, index=False, index_label=False)\n",
    "\n",
    "    # Distance and percentage for deforestation threshold\n",
    "    try:\n",
    "        index_thresh = np.nonzero(res_df[\"perc\"].values > defor_threshold)[0][0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Increase maximal distance defined in argument 'dist_bins'.\")\n",
    "\n",
    "    dist_thresh = res_df.loc[index_thresh, \"distance\"]\n",
    "    perc_thresh = np.around(res_df.loc[index_thresh, \"perc\"], 2)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    plt.subplot(111)\n",
    "    plt.plot(res_df[\"distance\"], res_df[\"perc\"], \"b-\")\n",
    "    plt.vlines(\n",
    "        dist_thresh,\n",
    "        ymin=np.min(res_df[\"perc\"]),\n",
    "        ymax=perc_thresh,\n",
    "        colors=\"k\",\n",
    "        linestyles=\"dashed\",\n",
    "    )\n",
    "    plt.hlines(perc_thresh, xmin=0, xmax=dist_thresh, colors=\"k\", linestyles=\"dashed\")\n",
    "    plt.xlabel(\"Distance to forest edge (m)\")\n",
    "    plt.ylabel(\"Percentage of total deforestation (%)\")\n",
    "    # Text distance\n",
    "    t1 = str(dist_thresh) + \" m\"\n",
    "    x1_text = dist_thresh - 0.01 * np.max(dist_bins)\n",
    "    y1_text = np.min(res_df[\"perc\"])\n",
    "    plt.text(x1_text, y1_text, t1, ha=\"right\", va=\"bottom\")\n",
    "    # Text percentage\n",
    "    t2 = str(perc_thresh) + \" %\"\n",
    "    x2_text = 0\n",
    "    y2_text = perc_thresh - 0.01 * (100 - np.min(res_df[\"perc\"]))\n",
    "    plt.text(x2_text, y2_text, t2, ha=\"left\", va=\"top\")\n",
    "    fig.savefig(fig_file_dist)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Results\n",
    "    return {\n",
    "        \"tot_def\": tot_area_def,\n",
    "        \"dist_thresh\": dist_thresh,\n",
    "        \"perc_thresh\": perc_thresh,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cf6ce-46db-47a2-960b-2da869134f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_dist_edge_threshold(\n",
    "    forest_change_file,\n",
    "    period_dictionary,\n",
    "    deforestation_thresh,\n",
    "    model_folder,\n",
    "    plots_folder,\n",
    "):\n",
    "    period_output_folder = model_folder / period_dictionary[\"period\"]\n",
    "    if not os.path.exists(period_output_folder):\n",
    "        os.makedirs(period_output_folder)\n",
    "    # dist_thresh = rmj.dist_edge_threshold(\n",
    "    dist_thresh = dist_edge_threshold_xarray_v2(\n",
    "        fcc_file=forest_change_file,\n",
    "        defor_values=period_dictionary[\"defor_value\"],\n",
    "        defor_threshold=deforestation_thresh,\n",
    "        dist_file=period_dictionary[\"initial_year_forest_edge\"],\n",
    "        # dist_bins=np.arange(0, max_dist, step=30),\n",
    "        tab_file_dist=period_output_folder / \"tab_dist.csv\",\n",
    "        fig_file_dist=plots_folder / f\"perc_dist_{period_dictionary['period']}.png\",\n",
    "        # blk_rows=128,\n",
    "        dist_file_available=True,\n",
    "        check_fcc=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    # Save result\n",
    "    dist_edge_data = pd.DataFrame(dist_thresh, index=[0])\n",
    "    dist_edge_data.to_csv(\n",
    "        period_output_folder / \"dist_edge_threshold.csv\",\n",
    "        sep=\",\",\n",
    "        header=True,\n",
    "        index=False,\n",
    "        index_label=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cd936-f4eb-45f8-bb4c-5f0010b6313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_dist_edge_threshold(\n",
    "    forest_change_file,\n",
    "    calibration_dict,\n",
    "    deforestation_thresh,\n",
    "    rmj_bm,\n",
    "    plots_folder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_dist_edge_threshold(\n",
    "    forest_change_file,\n",
    "    calibration_dict,\n",
    "    deforestation_thresh,\n",
    "    rmj_bm,\n",
    "    plots_folder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcacef7-89d0-4aef-a44d-20d1e51167ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_dist_edge_threshold(\n",
    "    forest_change_file,\n",
    "    historical_dict,\n",
    "    deforestation_thresh,\n",
    "    rmj_bm,\n",
    "    plots_folder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6d05c-99e0-480b-a5f0-82ff04ef109e",
   "metadata": {},
   "source": [
    "## 2 Compute bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdb380-bad0-4d7e-8c64-4fc2dfd5d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_thresh(ifile):\n",
    "    \"\"\"Get distance to forest edge threshold.\"\"\"\n",
    "    dist_thresh_data = pd.read_csv(ifile)\n",
    "    dist_thresh = dist_thresh_data.loc[0, \"dist_thresh\"]\n",
    "    return dist_thresh\n",
    "\n",
    "\n",
    "def save_dist_bins(dist_bins, output_file):\n",
    "    dist_bins_str = [str(i) for i in dist_bins]\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(dist_bins_str))\n",
    "\n",
    "\n",
    "def get_dist_bins(dist_bins_file):\n",
    "    \"\"\"Get distance bins.\"\"\"\n",
    "    with open(dist_bins_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        dist_bins = [float(line.rstrip()) for line in f]\n",
    "    return dist_bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dacaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute distance bins using rioxarray and dask.\n",
    "\"\"\"\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import math\n",
    "\n",
    "\n",
    "def compute_dist_bins(dist_file, dist_thresh):\n",
    "    \"\"\"Compute distance bins.\n",
    "\n",
    "    A geometric classification is used to convert distance to\n",
    "    forest edge into vulnerability classes.\n",
    "\n",
    "    :param dist_file: Distance to forest edge file.\n",
    "    :param dist_thresh: Distance threshold.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the distance raster using rioxarray\n",
    "    dist_ds = rioxarray.open_rasterio(dist_file, chunks=True)\n",
    "\n",
    "    # Get geotransform information\n",
    "    gt = dist_ds.rio.transform()\n",
    "    xres = abs(gt[0])  # Absolute value of x-resolution\n",
    "    yres = abs(gt[4])  # Absolute value of y-resolution\n",
    "\n",
    "    # Get minimum resolution\n",
    "    dist_min = min(xres, yres)\n",
    "\n",
    "    # Number of classes for geometric classification\n",
    "    n_classes = 29\n",
    "\n",
    "    # Calculate the ratio for geometric progression\n",
    "    ratio = math.pow(dist_min / dist_thresh, 1 / n_classes)\n",
    "\n",
    "    # Generate bins using geometric progression\n",
    "    bins = [dist_thresh * math.pow(ratio, n_classes - i) for i in range(n_classes + 1)]\n",
    "\n",
    "    # Correction for dist_min (as in original function)\n",
    "    bins[0] = dist_min\n",
    "\n",
    "    return bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c431b-024f-441a-9e1d-b64a649512da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_dist_bins(period_dictionary, model_folder):\n",
    "    period_output_folder = model_folder / period_dictionary[\"period\"]\n",
    "    period_dist_edge_file = period_output_folder / \"dist_edge_threshold.csv\"\n",
    "    # dist_bins = rmj.benchmark.compute_dist_bins(\n",
    "    dist_bins = compute_dist_bins(\n",
    "        period_dictionary.get(\"initial_year_forest_edge\"),\n",
    "        get_dist_thresh(period_dist_edge_file),\n",
    "    )\n",
    "    dist_thresh = get_dist_thresh(period_dist_edge_file)\n",
    "    dist_bins_file = period_output_folder / \"dist_bins.csv\"\n",
    "    save_dist_bins(dist_bins, dist_bins_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd9853-c10d-414c-96cc-0bc0a577f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_dist_bins(calibration_dict, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dac5d1-00bd-4a0c-a7a2-8da61a36e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_dist_bins(historical_dict, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b815c3-065b-4621-bcc2-811804a507db",
   "metadata": {},
   "source": [
    "## 3 Compute vulnerability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90692b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Map with vulnerability classes using rioxarray and dask.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def vulnerability_map_xarray(\n",
    "    forest_file,\n",
    "    dist_file,\n",
    "    dist_bins,\n",
    "    subj_file,\n",
    "    output_file=\"vulnerability_map.tif\",\n",
    "    blk_rows=128,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"Map with vulnerability classes.\n",
    "\n",
    "    A raster file with vulnerability classes is created combining distance\n",
    "    to forest edge classes and subjurisdiction identifiers. High\n",
    "    values indicate higher vulnerability. Raster type is UInt16 ([0,\n",
    "    65535]). NoData value is set to 0.\n",
    "\n",
    "    :param forest_file: Input forest cover file. Necessary to have\n",
    "        forest extent within country borders (info not provided by\n",
    "        dist_file).\n",
    "\n",
    "    :param dist_file: Input file of distance to forest edge.\n",
    "\n",
    "    :param dist_bins: The distance bins used to convert distance to\n",
    "        forest edge into vulnerability classes. The first value\n",
    "        indicates the minimal distance and the last value indicates\n",
    "        the distance threshold.\n",
    "\n",
    "    :param subj_file: Input raster file with subjurisdiction\n",
    "        identifiers.\n",
    "\n",
    "    :param blk_rows: If > 0, number of rows for computation by block.\n",
    "\n",
    "    :param verbose: Logical. Whether to print messages or not. Default\n",
    "        to ``True``.\n",
    "\n",
    "    :return: Bins used to categorize the deforestation risk based on\n",
    "        the distance to forest edge.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # ==============================================================\n",
    "    # Input rasters\n",
    "    # ==============================================================\n",
    "\n",
    "    # Read all input files with chunking for large datasets\n",
    "    forest_ds = rioxarray.open_rasterio(forest_file, chunks=True)\n",
    "    dist_ds = rioxarray.open_rasterio(dist_file, chunks=True)\n",
    "    subj_ds = rioxarray.open_rasterio(subj_file, chunks=True)\n",
    "\n",
    "    # Distance info from bins\n",
    "    n_classes = len(dist_bins) - 1\n",
    "    dist_thresh = dist_bins[-1]\n",
    "\n",
    "    # =================================================\n",
    "    # Categorical raster file for vulnerability classes\n",
    "    # =================================================\n",
    "\n",
    "    # Get the first band of each dataset (assuming single band)\n",
    "    forest_data = forest_ds.squeeze()\n",
    "    dist_data = dist_ds.squeeze()\n",
    "    subj_data = subj_ds.squeeze()\n",
    "\n",
    "    # Categorize distance to forest edge using pandas cut function\n",
    "    # Convert to numpy arrays for processing (this will trigger computation)\n",
    "    dist_array = dist_data.values\n",
    "    forest_array = forest_data.values\n",
    "    subj_array = subj_data.values\n",
    "\n",
    "    # Categorize using pandas cut function\n",
    "    # cat_data = pd.cut(\n",
    "    #     dist_array.flatten(),\n",
    "    #     bins=dist_bins,\n",
    "    #     labels=False,\n",
    "    #     include_lowest=True,\n",
    "    #     right=True,\n",
    "    # )\n",
    "    # cat_data = cat_data.reshape(dist_array.shape)\n",
    "\n",
    "    # With a more direct NumPy approach:\n",
    "    cat_data = np.digitize(dist_array, dist_bins, right=True)\n",
    "\n",
    "    # Reverse the category order (higher vulnerability = higher class)\n",
    "    cat_data = n_classes + 1 - cat_data\n",
    "\n",
    "    # Set classes 1 beyond distance threshold\n",
    "    cat_data[dist_array > dist_thresh] = 1\n",
    "    cat_data[forest_array == 0] = 0  # Mask with forest\n",
    "\n",
    "    # Add subjurisdiction info\n",
    "    cat_data = cat_data * 1000 + subj_array\n",
    "    cat_data[cat_data <= 1000] = 0\n",
    "\n",
    "    # Create output dataset with same dimensions and metadata\n",
    "    output_da = xr.full_like(forest_data, 0, dtype=\"uint16\")\n",
    "    output_da.values = cat_data.astype(\"uint16\")\n",
    "\n",
    "    # Set NoData value explicitly to match GDAL behavior\n",
    "    output_da.rio.write_nodata(0, inplace=True)\n",
    "\n",
    "    # Save the output file using rioxarray's efficient raster writing capabilities\n",
    "    from dask.distributed import Lock\n",
    "\n",
    "    output_da.rio.to_raster(\n",
    "        output_file,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "        lock=Lock(\"rio\"),\n",
    "    )\n",
    "\n",
    "    # Return bins used (same as original function)\n",
    "    return dist_bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf33169-a381-44da-a8d0-7684783668ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_vulnerability_map(\n",
    "    period_dictionary, raster_subj_file, model_folder\n",
    "):\n",
    "    period_output_folder = model_folder / period_dictionary[\"period\"]\n",
    "    if not os.path.exists(period_output_folder):\n",
    "        os.makedirs(period_output_folder)\n",
    "    trained_period_output_folder = model_folder / period_dictionary[\"train_period\"]\n",
    "    dist_bins_file = trained_period_output_folder / \"dist_bins.csv\"\n",
    "    vulnerability_map_file = (\n",
    "        period_output_folder / f\"prob_bm_{period_dictionary['period']}.tif\"\n",
    "    )\n",
    "\n",
    "    # rmj.benchmark.vulnerability_map(\n",
    "    vulnerability_map_xarray(\n",
    "        forest_file=period_dictionary[\"initial_year_forest\"],\n",
    "        dist_file=period_dictionary[\"initial_year_forest_edge\"],\n",
    "        dist_bins=get_dist_bins(dist_bins_file),\n",
    "        subj_file=raster_subj_file,\n",
    "        output_file=vulnerability_map_file,\n",
    "        blk_rows=128,\n",
    "        verbose=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883b5b4-7926-402b-92c2-186b229b7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_map(calibration_dict, raster_subj_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767d434-bfe9-420b-8ee3-25feb2d4ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_map(historical_dict, raster_subj_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3133008-9b6e-45ca-9cb5-7867ce36665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_map(validation_dict, raster_subj_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b5ae9-c0d0-47f9-b2e9-53387b420fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_map(forecast_dict, raster_subj_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee7673-0434-4b63-95cd-9f52a1965073",
   "metadata": {},
   "source": [
    "## 4 Compute deforestation rate per vulnerability class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute deforestation rates per vulnerability class using xarray with Dask.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def defrate_per_class_xarray(\n",
    "    fcc_file,\n",
    "    vulnerability_file,\n",
    "    time_interval,\n",
    "    period=\"calibration\",\n",
    "    deforate_model=None,\n",
    "    tab_file_defrate=\"defrate_per_class.csv\",\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute deforestation rates per vulnerability class using xarray with Dask.\n",
    "\n",
    "    This function computes the historical deforestation rates for each\n",
    "    vulnerability class using modern geospatial libraries with parallel processing.\n",
    "\n",
    "    A ``.csv`` file with deforestation rates for each vulnerability\n",
    "    class is created (see ``tab_file_defrate``).\n",
    "\n",
    "    :param fcc_file: Input raster file of forest cover change at three\n",
    "        dates (123). 1: first period deforestation, 2: second period\n",
    "        deforestation, 3: remaining forest at the end of the second\n",
    "        period. No data value must be 0 (zero).\n",
    "\n",
    "    :param vulnerability_file: Input file with vulnerability classes.\n",
    "\n",
    "    :param time_interval: Time interval (in years) for forest cover\n",
    "        change observations.\n",
    "\n",
    "    :param period: Either \"calibration\" (from t1 to t2), \"validation\"\n",
    "        (or \"confirmation\" from t2 to t3), or \"historical\" (full\n",
    "        historical period from t1 to t3). Default to \"calibration\".\n",
    "\n",
    "    :param deforate_model: Path to the ``.csv`` input file with\n",
    "        deforestation rates per class from the model's period\n",
    "        (either \"calibration\" or \"historical\" period). Used for\n",
    "        estimating deforestation for the \"validation\" or \"forecast\"\n",
    "        period after quantity adjustment.\n",
    "\n",
    "    :param tab_file_defrate: Path to the ``.csv`` output file with\n",
    "        estimates of deforestation rates for each vulnerability class.\n",
    "\n",
    "    :param verbose: Logical. Whether to print messages or not. Default\n",
    "        to ``True``.\n",
    "    \"\"\"\n",
    "\n",
    "    # ==============================================================\n",
    "    # Input rasters using xarray/rioxarray with Dask chunking\n",
    "    # ==============================================================\n",
    "\n",
    "    # Open files with rioxarray using Dask chunks for parallel processing\n",
    "    fcc_ds = rioxarray.open_rasterio(fcc_file, chunks=True)\n",
    "    defor_cat_ds = rioxarray.open_rasterio(vulnerability_file, chunks=True)\n",
    "\n",
    "    # Get spatial information\n",
    "    xres = abs(fcc_ds.rio.resolution()[0])\n",
    "    yres = abs(fcc_ds.rio.resolution()[1])\n",
    "\n",
    "    # ==============================================\n",
    "    # Compute deforestation rates per cat using Dask\n",
    "    # ==============================================\n",
    "\n",
    "    # Get unique categories from vulnerability raster (more efficient than hardcoding)\n",
    "    unique_cats = np.unique(defor_cat_ds.values[defor_cat_ds.values != 0])\n",
    "    unique_cats = unique_cats[unique_cats > 0]  # Remove 0s if any\n",
    "\n",
    "    # Create a table to save the results\n",
    "    data = {\"cat\": unique_cats, \"nfor\": 0, \"ndefor\": 0}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Process the entire dataset using Dask for parallel computation\n",
    "    # This automatically handles chunking and parallel processing\n",
    "\n",
    "    # Defor data on period - use vectorized operations for efficiency\n",
    "    if period == \"calibration\":\n",
    "        data_for = defor_cat_ds.where(fcc_ds > 0).values.flatten()\n",
    "        data_defor = defor_cat_ds.where(fcc_ds == 1).values.flatten()\n",
    "    elif period == \"validation\":\n",
    "        data_for = defor_cat_ds.where(fcc_ds > 1).values.flatten()\n",
    "        data_defor = defor_cat_ds.where(fcc_ds == 2).values.flatten()\n",
    "    else:  # historical or forecast\n",
    "        data_for = defor_cat_ds.where(fcc_ds > 0).values.flatten()\n",
    "        data_defor = defor_cat_ds.where((fcc_ds == 1) | (fcc_ds == 2)).values.flatten()\n",
    "\n",
    "    # Remove NaN values (which represent no-data areas)\n",
    "    data_for = data_for[~np.isnan(data_for)]\n",
    "    data_defor = data_defor[~np.isnan(data_defor)]\n",
    "\n",
    "    # Count occurrences by category using pandas for efficiency\n",
    "    # Convert to Series and use value_counts for better performance\n",
    "    cat_for_series = pd.Series(data_for.astype(int))\n",
    "    cat_defor_series = pd.Series(data_defor.astype(int))\n",
    "\n",
    "    # Get counts for each category\n",
    "    nfor_counts = cat_for_series.value_counts()\n",
    "    ndefor_counts = cat_defor_series.value_counts()\n",
    "\n",
    "    # Update the DataFrame with actual counts\n",
    "    for cat in unique_cats:\n",
    "        df.loc[df[\"cat\"] == cat, \"nfor\"] = nfor_counts.get(cat, 0)\n",
    "        df.loc[df[\"cat\"] == cat, \"ndefor\"] = ndefor_counts.get(cat, 0)\n",
    "\n",
    "    # Remove classes with no forest\n",
    "    df = df[df[\"nfor\"] != 0]\n",
    "\n",
    "    # Annual deforestation rates per category (just for info)\n",
    "    df[\"rate_obs\"] = 1 - (1 - df[\"ndefor\"] / df[\"nfor\"]) ** (1 / time_interval)\n",
    "\n",
    "    # Relative deforestation rate from model (not annual)\n",
    "    if period in [\"validation\", \"forecast\"]:\n",
    "        df_mod = pd.read_csv(deforate_model)\n",
    "        # Join the tables to get rate_mod.\n",
    "        df = df.merge(right=df_mod, on=\"cat\", how=\"left\", suffixes=(None, \"_mod\"))\n",
    "    else:\n",
    "        df[\"rate_mod\"] = df[\"ndefor\"] / df[\"nfor\"]\n",
    "\n",
    "    # Correction factor, either ndefor / sum_i p_i\n",
    "    # or theta * nfor / sum_i p_i\n",
    "    sum_ndefor = df[\"ndefor\"].sum()\n",
    "    sum_pi = (df[\"nfor\"] * df[\"rate_mod\"]).sum()\n",
    "    correction_factor = sum_ndefor / sum_pi\n",
    "\n",
    "    # Absolute deforestation probability\n",
    "    # With quantity adjustment\n",
    "    df[\"rate_abs\"] = df[\"rate_mod\"] * correction_factor\n",
    "\n",
    "    # Time interval\n",
    "    df[\"time_interval\"] = time_interval\n",
    "\n",
    "    # Pixel area\n",
    "    pixel_area = xres * yres / 10000\n",
    "    df[\"pixel_area\"] = pixel_area\n",
    "\n",
    "    # Deforestation density (ha/pixel/yr)\n",
    "    df[\"defor_dens\"] = df[\"rate_abs\"] * pixel_area / time_interval\n",
    "\n",
    "    # Export the table of results\n",
    "    df.to_csv(tab_file_defrate, sep=\",\", header=True, index=False, index_label=False)\n",
    "\n",
    "    # Clean up - in xarray this is handled automatically but good to be explicit\n",
    "    fcc_ds.close()\n",
    "    defor_cat_ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defrate_per_class_xarray_v2(\n",
    "    fcc_file,\n",
    "    vulnerability_file,\n",
    "    time_interval,\n",
    "    period=\"calibration\",\n",
    "    deforate_model=None,\n",
    "    tab_file_defrate=\"defrate_per_class.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Final optimized implementation with minimal pandas usage.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open files with rioxarray\n",
    "    fcc_ds = rioxarray.open_rasterio(fcc_file, chunks=True)\n",
    "    defor_cat_ds = rioxarray.open_rasterio(vulnerability_file, chunks=True)\n",
    "\n",
    "    # Get spatial information\n",
    "    xres = abs(fcc_ds.rio.resolution()[0])\n",
    "    yres = abs(fcc_ds.rio.resolution()[1])\n",
    "\n",
    "    # Convert to dask arrays for computation\n",
    "    fcc_da = fcc_ds.data\n",
    "    defor_cat_da = defor_cat_ds.data\n",
    "\n",
    "    # Get unique categories efficiently using Dask\n",
    "    unique_cats = da.unique(defor_cat_da[defor_cat_da != 0]).compute()\n",
    "    unique_cats = unique_cats[unique_cats > 0]\n",
    "\n",
    "    # Process based on period\n",
    "    if period == \"calibration\":\n",
    "        data_for_mask = fcc_da > 0\n",
    "        data_defor_mask = fcc_da == 1\n",
    "    elif period == \"validation\":\n",
    "        data_for_mask = fcc_da > 1\n",
    "        data_defor_mask = fcc_da == 2\n",
    "    else:  # historical or forecast\n",
    "        data_for_mask = fcc_da > 0\n",
    "        data_defor_mask = (fcc_da == 1) | (fcc_da == 2)\n",
    "\n",
    "    # Apply masks using dask where function and flatten\n",
    "    data_for = da.where(data_for_mask, defor_cat_da, np.nan).flatten()\n",
    "    data_defor = da.where(data_defor_mask, defor_cat_da, np.nan).flatten()\n",
    "\n",
    "    # Remove NaN values and count efficiently\n",
    "    valid_for = data_for[~da.isnan(data_for)]\n",
    "    valid_defor = data_defor[~da.isnan(data_defor)]\n",
    "\n",
    "    # Count categories (this is where we use pandas but only for final result)\n",
    "    # Convert back to numpy arrays for counting with pandas\n",
    "    nfor_counts = pd.Series(valid_for.compute().astype(int)).value_counts()\n",
    "    ndefor_counts = pd.Series(valid_defor.compute().astype(int)).value_counts()\n",
    "\n",
    "    # Create results DataFrame (minimal pandas usage)\n",
    "    data = {\n",
    "        \"cat\": unique_cats,\n",
    "        \"nfor\": [nfor_counts.get(cat, 0) for cat in unique_cats],\n",
    "        \"ndefor\": [ndefor_counts.get(cat, 0) for cat in unique_cats],\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Remove classes with no forest\n",
    "    df = df[df[\"nfor\"] != 0]\n",
    "\n",
    "    # Continue with remaining computations\n",
    "    df[\"rate_obs\"] = 1 - (1 - df[\"ndefor\"] / df[\"nfor\"]) ** (1 / time_interval)\n",
    "\n",
    "    if period in [\"validation\", \"forecast\"]:\n",
    "        df_mod = pd.read_csv(deforate_model)\n",
    "        df = df.merge(right=df_mod, on=\"cat\", how=\"left\", suffixes=(None, \"_mod\"))\n",
    "    else:\n",
    "        df[\"rate_mod\"] = df[\"ndefor\"] / df[\"nfor\"]\n",
    "\n",
    "    sum_ndefor = df[\"ndefor\"].sum()\n",
    "    sum_pi = (df[\"nfor\"] * df[\"rate_mod\"]).sum()\n",
    "    correction_factor = sum_ndefor / sum_pi\n",
    "\n",
    "    df[\"rate_abs\"] = df[\"rate_mod\"] * correction_factor\n",
    "    df[\"time_interval\"] = time_interval\n",
    "\n",
    "    pixel_area = xres * yres / 10000\n",
    "    df[\"pixel_area\"] = pixel_area\n",
    "    df[\"defor_dens\"] = df[\"rate_abs\"] * pixel_area / time_interval\n",
    "\n",
    "    # Export results\n",
    "    df.to_csv(tab_file_defrate, sep=\",\", header=True, index=False, index_label=False)\n",
    "\n",
    "    fcc_ds.close()\n",
    "    defor_cat_ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378974be-542b-4c11-9325-c53fd51e2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_vulnerability_classes(\n",
    "    period_dictionary, forest_change_file, model_folder\n",
    "):\n",
    "    period_output_folder = model_folder / period_dictionary[\"period\"]\n",
    "    trained_period_output_folder = model_folder / period_dictionary[\"train_period\"]\n",
    "    vulnerability_file_path = (\n",
    "        period_output_folder / f\"prob_bm_{period_dictionary['period']}.tif\"\n",
    "    )\n",
    "    time_interval = period_dictionary[\"time_interval\"]\n",
    "    if period_dictionary[\"period\"] in [\"validation\", \"forecast\"]:\n",
    "        deforate_model = (\n",
    "            trained_period_output_folder\n",
    "            / f\"defrate_cat_bm_{period_dictionary['train_period']}.csv\"\n",
    "        )\n",
    "    else:\n",
    "        deforate_model = None\n",
    "    output_file = (\n",
    "        period_output_folder / f\"defrate_cat_bm_{period_dictionary['period']}.csv\"\n",
    "    )\n",
    "    # rmj.benchmark.defrate_per_class(\n",
    "    defrate_per_class_xarray_v2(\n",
    "        fcc_file=forest_change_file,\n",
    "        vulnerability_file=vulnerability_file_path,\n",
    "        time_interval=period_dictionary[\"time_interval\"],\n",
    "        period=period_dictionary[\"period\"],\n",
    "        deforate_model=deforate_model,\n",
    "        tab_file_defrate=output_file,\n",
    "        # blk_rows=128,\n",
    "        # verbose=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a234ad9-9baa-466e-be32-80b72ba38185",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_classes(calibration_dict, forest_change_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec748e6-112f-456e-be8a-4c7aa680263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_classes(historical_dict, forest_change_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa8739-f84e-4194-83b2-4ae908d9320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_classes(validation_dict, forest_change_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f6790-98b3-4643-b28a-fe7b89944088",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_vulnerability_classes(forecast_dict, forest_change_file, rmj_bm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b59aa-bec6-442a-8eb2-055c76fc32d8",
   "metadata": {},
   "source": [
    "## 5 Plot Risk map of deforestation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898f2de-814e-440c-b646-b85d6aa45245",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector_files = list_files_by_extension(processed_data_folder, [\".shp\"])\n",
    "aoi_vector = filter_files_by_keywords(input_vector_files, [\"aoi\"])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_plot = os.path.join(plots_folder, \"fcc123.png\")\n",
    "fig_fcc123 = rmj.plot.fcc123(\n",
    "    input_fcc_raster=forest_change_file,\n",
    "    maxpixels=1e8,\n",
    "    output_file=fcc_plot,\n",
    "    borders=aoi_vector,\n",
    "    linewidth=0.2,\n",
    "    figsize=(5, 4),\n",
    "    dpi=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa786b4-5157-4e1f-ab1b-9964bb99b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_period_plot_risk_map(\n",
    "    period_dictionary, aoi_vector, model_folder, plots_folder\n",
    "):\n",
    "    period_output_folder = model_folder / period_dictionary[\"period\"]\n",
    "    ifile = str(period_output_folder / f\"prob_bm_{period_dictionary['period']}.tif\")\n",
    "    # ofile = period_output_folder /  f\"prob_bm_{period_dictionary['period']}.png\n",
    "    ofile = str(plots_folder / f\"prob_bm_{period_dictionary['period']}.png\")\n",
    "    riskmap_fig = rmj.benchmark.plot.vulnerability_map(\n",
    "        input_map=ifile,\n",
    "        maxpixels=1e8,\n",
    "        output_file=ofile,\n",
    "        borders=aoi_vector,\n",
    "        legend=True,\n",
    "        figsize=(6, 5),\n",
    "        dpi=300,\n",
    "        linewidth=0.3,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57482fde-d6f4-4cd9-8a07-3e959ca2f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_plot_risk_map(calibration_dict, aoi_vector, rmj_bm, plots_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3b1b-9c38-40ac-bd5f-2fbb7a1e2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_plot_risk_map(historical_dict, aoi_vector, rmj_bm, plots_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326bee3-f99c-42a8-a91b-5c9b7470878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_plot_risk_map(validation_dict, aoi_vector, rmj_bm, plots_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4266dc1-5a8b-4c9a-ab34-4c44094e3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_period_plot_risk_map(forecast_dict, aoi_vector, rmj_bm, plots_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2db9f-4efd-4164-b602-05bfaadf7a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deforisk-jupyter-nb (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
